{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Hello world\n",
    "\n",
    "In this unit you will learn how to use Python to implement the first ever program\n",
    "that *every* programmer starts with. This also serves as an example for the master\n",
    "notebook format.\n",
    "\n",
    "```\n",
    "# All markdown cells are searched for triple-backtick blocks. Within a triple quoted block,\n",
    "# a match on /^# ASSIGNMENT METADATA/ will trigger handling this as an assignment-level metadata\n",
    "# block. The rest of the metadata is parsed as YAML and may be used e.g. for setting\n",
    "# default settings for autograder isolation (memory limit etc).\n",
    "# The assignment_id is useful to identify which assignment a submission pertains to.\n",
    "# ASSIGNMENT METADATA\n",
    "assignment_id: \"HelloWorld\"\n",
    "```\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Here is the traditional first programming exercise, called \"Hello world\".\n",
    "The task is to print the message: \"Hello, world\".\n",
    "\n",
    "Here are a few examples to get you started. Run the following cells and see how\n",
    "you can print a message. To run a cell, click with mouse inside a cell, then\n",
    "press Ctrl+Enter to execute it. If you want to execute a few cells sequentially,\n",
    "then press Shift+Enter instead, and the focus will be automatically moved\n",
    "to the next cell as soon as one cell finishes execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bye bye\n"
     ]
    }
   ],
   "source": [
    "print(\"bye bye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey you\n"
     ]
    }
   ],
   "source": [
    "print(\"hey\", \"you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n",
      "two\n"
     ]
    }
   ],
   "source": [
    "print(\"one\")\n",
    "print(\"two\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: printing greeting\n",
    "\n",
    "```\n",
    "# The markdown cell with triple-backtick block matching /^# EXERCISE METADATA/ is an exercise-level\n",
    "# metadata. The next block is assumed to be the solution block, and will get annotated with\n",
    "# the exercise_id.\n",
    "# EXERCISE METADATA\n",
    "exercise_id: \"hello1\"\n",
    "```\n",
    "\n",
    "Now it is your turn. Please create a program in the next cell that would print a message \"Hello, world\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # BEGIN PROMPT\n",
    "   # ... put your program here\n",
    "   pass\n",
    "\"\"\" # END PROMPT\n",
    "def printHello():\n",
    "    # BEGIN SOLUTION\n",
    "    print(\"Hello, world\")\n",
    "    # END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_output (__main__.HelloOutputTest) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "{'HelloOutputTest.test_output': True}\n"
     ]
    }
   ],
   "source": [
    "# This will not be included in the student notebook because of BEGIN UNITTEST marker below.\n",
    "\n",
    "# Imitate the 'import submission' environment with ad-hoc object.\n",
    "from types import SimpleNamespace\n",
    "submission = SimpleNamespace(printHello=printHello)\n",
    "\n",
    "# BEGIN UNITTEST\n",
    "import unittest\n",
    "\n",
    "import sys\n",
    "import io\n",
    "from contextlib import contextmanager\n",
    "from io import StringIO\n",
    "\n",
    "@contextmanager\n",
    "def capture_output():\n",
    "    capture_out, capture_err = StringIO(), StringIO()\n",
    "    save_out, save_err = sys.stdout, sys.stderr\n",
    "    try:\n",
    "        sys.stdout, sys.stderr = capture_out, capture_err\n",
    "        yield sys.stdout, sys.stderr\n",
    "    finally:\n",
    "        sys.stdout, sys.stderr = save_out, save_err\n",
    "\n",
    "class HelloOutputTest(unittest.TestCase):\n",
    "    def test_output(self):\n",
    "        with capture_output() as (out, err):\n",
    "            submission.printHello()\n",
    "        self.assertEqual(err.getvalue(), \"\")\n",
    "        self.assertEqual(out.getvalue(), \"Hello, world\\n\")\n",
    "\n",
    "# END UNITTEST\n",
    "\n",
    "# The parts after END UNITTEST are executed in the notebook environment, but not copied\n",
    "# to the autograder scripts or to student notebooks.\n",
    "\n",
    "# TODO(salikh): Move this into a shared library and make that library installable via pip.\n",
    "class SummaryTestResult(unittest.TextTestResult):\n",
    "    \"\"\"A small extension of TextTestResult that also collects a map of test statuses.\n",
    "    \n",
    "    \n",
    "    result.results is a map from test name (string) to boolean: True(passed) or False(failed or error)\"\"\"\n",
    "    \n",
    "    separator1 = '=' * 70\n",
    "    separator2 = '-' * 70\n",
    "    \n",
    "    def __init__(self, stream, descriptions, verbosity):\n",
    "        super(unittest.TextTestResult, self).__init__(stream, descriptions, verbosity)\n",
    "        # A map of test name to True(passed) or False(failed or error)\n",
    "        self.results = {}\n",
    "        # Copied from TextTestResult.\n",
    "        self.stream = stream\n",
    "        self.showAll = verbosity > 1\n",
    "        self.dots = verbosity == 1\n",
    "        self.descriptions = descriptions\n",
    "\n",
    "    def testName(self, test):\n",
    "        \"\"\"A helper function to format the test as a human-readable string.\n",
    "        \n",
    "        The format is TestClassName.test_method. This is similar\n",
    "        to TextTestResult.getDescription(test), but uses different format.\n",
    "        getDescription: 'test_one (__main__.HelloTest)'\n",
    "        testName: 'HelloTest.test_one'\n",
    "        \"\"\"\n",
    "        return unittest.util.strclass(test.__class__).replace('__main__.', '') + '.' + test._testMethodName\n",
    "        \n",
    "    def getDescription(self, test):\n",
    "        doc_first_line = test.shortDescription()\n",
    "        if self.descriptions and doc_first_line:\n",
    "            return '\\n'.join((str(test), doc_first_line))\n",
    "        else:\n",
    "            return str(test)\n",
    "\n",
    "    def startTest(self, test):\n",
    "        super(unittest.TextTestResult, self).startTest(test)\n",
    "        if self.showAll:\n",
    "            self.stream.write(self.getDescription(test))\n",
    "            self.stream.write(\" ... \")\n",
    "            self.stream.flush()\n",
    "\n",
    "    def addSuccess(self, test):\n",
    "        super(unittest.TextTestResult, self).addSuccess(test)\n",
    "        if self.showAll:\n",
    "            self.stream.writeln(\"ok\")\n",
    "        elif self.dots:\n",
    "            self.stream.write('.')\n",
    "            self.stream.flush()\n",
    "        self.results[self.testName(test)] = True\n",
    "\n",
    "    def addError(self, test, err):\n",
    "        super(unittest.TextTestResult, self).addError(test, err)\n",
    "        if self.showAll:\n",
    "            self.stream.writeln(\"ERROR\")\n",
    "        elif self.dots:\n",
    "            self.stream.write('E')\n",
    "            self.stream.flush()\n",
    "        self.results[self.testName(test)] = False\n",
    "\n",
    "    def addFailure(self, test, err):\n",
    "        super(unittest.TextTestResult, self).addFailure(test, err)\n",
    "        if self.showAll:\n",
    "            self.stream.writeln(\"FAIL\")\n",
    "        elif self.dots:\n",
    "            self.stream.write('F')\n",
    "            self.stream.flush()\n",
    "        self.results[self.testName(test)] = False\n",
    "\n",
    "    def addSkip(self, test, reason):\n",
    "        super(unittest.TextTestResult, self).addSkip(test, reason)\n",
    "        if self.showAll:\n",
    "            self.stream.writeln(\"skipped {0!r}\".format(reason))\n",
    "        elif self.dots:\n",
    "            self.stream.write(\"s\")\n",
    "            self.stream.flush()\n",
    "\n",
    "    def addExpectedFailure(self, test, err):\n",
    "        super(unittest.TextTestResult, self).addExpectedFailure(test, err)\n",
    "        if self.showAll:\n",
    "            self.stream.writeln(\"expected failure\")\n",
    "        elif self.dots:\n",
    "            self.stream.write(\"x\")\n",
    "            self.stream.flush()\n",
    "\n",
    "    def addUnexpectedSuccess(self, test):\n",
    "        super(unittest.TextTestResult, self).addUnexpectedSuccess(test)\n",
    "        if self.showAll:\n",
    "            self.stream.writeln(\"unexpected success\")\n",
    "        elif self.dots:\n",
    "            self.stream.write(\"u\")\n",
    "            self.stream.flush()\n",
    "\n",
    "    def printErrors(self):\n",
    "        if self.dots or self.showAll:\n",
    "            self.stream.writeln()\n",
    "        self.printErrorList('ERROR', self.errors)\n",
    "        self.printErrorList('FAIL', self.failures)\n",
    "\n",
    "    def printErrorList(self, flavour, errors):\n",
    "        for test, err in errors:\n",
    "            self.stream.writeln(self.separator1)\n",
    "            self.stream.writeln(\"%s: %s\" % (flavour,self.getDescription(test)))\n",
    "            self.stream.writeln(self.separator2)\n",
    "            self.stream.writeln(\"%s\" % err)\n",
    "\n",
    "import sys\n",
    "import io\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(HelloOutputTest)\n",
    "errors = io.StringIO()\n",
    "result = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\n",
    "# Optional.\n",
    "print(errors.getvalue())\n",
    "\n",
    "print(result.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: returning greeting as value\n",
    "\n",
    "```\n",
    "# EXERCISE METADATA\n",
    "exercise_id: \"hello2\"\n",
    "```\n",
    "\n",
    "Please create a function that given a name string returns a string with a greeting,\n",
    "For example, for input `\"world\"` it should return `\"Hello, world\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello(name):\n",
    "    \"\"\" # BEGIN PROMPT\n",
    "    # Please put your solution here:\n",
    "    # return ...\n",
    "    pass\n",
    "    \"\"\" # END PROMPT\n",
    "    # BEGIN SOLUTION\n",
    "    return \"Hello, \" + name\n",
    "    # END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert(hello(\"world\") == \"Hello, world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A code cell marked with `\"# TEST\"` will be converted into a unit test for the solution. It will also be preserved in the student version of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_bad (__main__.HelloTest) ... FAIL\n",
      "test_one (__main__.HelloTest) ... ok\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_bad (__main__.HelloTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-64-6dbf578cd0e2>\", line 18, in test_bad\n",
      "    self.assertEqual(submission.hello(\"bad\"), \"Hello, good\")\n",
      "AssertionError: 'Hello, bad' != 'Hello, good'\n",
      "- Hello, bad\n",
      "?        ^^\n",
      "+ Hello, good\n",
      "?        ^^^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "{'HelloTest.test_bad': False, 'HelloTest.test_one': True}\n"
     ]
    }
   ],
   "source": [
    "# The part before \"BEGIN UNITTEST\" -- preamble -- sets up the environment so that 'submission.hello'\n",
    "# is a function that we need to test. In the autograder worker environment, the preamble will be\n",
    "# replaced with 'import submission' with an assumption that the student's solution will be written\n",
    "# to the file 'submission.py'.\n",
    "submission = SimpleNamespace(hello=hello)\n",
    "\n",
    "# BEGIN UNITTEST\n",
    "# The unit tests main part is contained between \"BEGIN UNITTEST\" and \"END UNITTEST\". It will be copied\n",
    "# verbatim into the autograder directory, with an addition of 'import submission'\n",
    "\n",
    "import unittest\n",
    "\n",
    "class HelloTest(unittest.TestCase):\n",
    "    def test_one(self):\n",
    "        self.assertEqual(submission.hello(\"one\"), \"Hello, one\")\n",
    "        \n",
    "    def test_bad(self):\n",
    "        self.assertEqual(submission.hello(\"bad\"), \"Hello, good\")\n",
    "        \n",
    "# END UNITTEST\n",
    "\n",
    "import sys\n",
    "import io\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\n",
    "errors = io.StringIO()\n",
    "result = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\n",
    "# Optional.\n",
    "print(errors.getvalue())\n",
    "\n",
    "print(result.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HelloTest.test_bad': False, 'HelloTest.test_one': False}\n"
     ]
    }
   ],
   "source": [
    "# BEGIN AUTOTEST\n",
    "# The tests below test that the unit test suite above produces expected outcomes from\n",
    "# TODO(salikh): Figure out the right syntax for autotests.\n",
    "def wrong_hello(name):\n",
    "    return \"Bye, \" + name\n",
    "\n",
    "import unittest\n",
    "\n",
    "submission.hello = wrong_hello\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\n",
    "errors = io.StringIO()\n",
    "result = unittest.TextTestRunner(verbosity=4,stream=errors,  resultclass=SummaryTestResult).run(suite)\n",
    "\n",
    "print(result.results)\n",
    "assert(result.results['HelloTest.test_bad'] == False)\n",
    "assert(result.results['HelloTest.test_one'] == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import (register_line_magic, register_cell_magic,\n",
    "                                register_line_cell_magic)\n",
    "\n",
    "@register_cell_magic\n",
    "def submission(line, cell):\n",
    "    \"\"\"A magic to mark a textual submission, possibly incorrect and unparseable.\"\"\"\n",
    "    return cell\n",
    "\n",
    "@register_line_magic\n",
    "def autotest(line):\n",
    "    \"\"\"A magic to run an auto test: run previously defined unit tests with a submission just given.\"\"\"\n",
    "    return eval(line)\n",
    "\n",
    "del submission, autotest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def syntax_error(name:\\n    return name\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%submission\n",
    "def syntax_error(name:\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.HelloTest"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = %autotest HelloTest\n",
    "result\n",
    "#assert(result['HelloTest.test_bad'] == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import (register_line_magic, register_cell_magic,\n",
    "                                register_line_cell_magic)\n",
    "\n",
    "@register_line_magic\n",
    "def lmagic(line):\n",
    "    \"my line magic\"\n",
    "    return line\n",
    "\n",
    "@register_cell_magic\n",
    "def cmagic(line, cell):\n",
    "    \"my cell magic\"\n",
    "    return cell\n",
    "\n",
    "del lmagic, cmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, a b c\n"
     ]
    }
   ],
   "source": [
    "x = %lmagic a b c\n",
    "print(\"Hello, \" +x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my cell magic\\nasfd\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%cmagic\n",
    "my cell magic\n",
    "asfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': '__main__',\n",
       " '__doc__': ' # BEGIN PROMPT\\n   # ... put your program here\\n   pass\\n',\n",
       " '__package__': None,\n",
       " '__loader__': None,\n",
       " '__spec__': None,\n",
       " '__builtin__': <module 'builtins' (built-in)>,\n",
       " '__builtins__': <module 'builtins' (built-in)>,\n",
       " '_ih': ['',\n",
       "  'print(\"hello\")',\n",
       "  'print(\"bye bye\")',\n",
       "  'print(\"hey\", \"you\")',\n",
       "  'print(\"one\")\\nprint(\"two\")',\n",
       "  '\"\"\" # BEGIN PROMPT\\n   # ... put your program here\\n   pass\\n\"\"\" # END PROMPT\\ndef printHello():\\n    # BEGIN SOLUTION\\n    print(\"Hello, world\")\\n    # END SOLUTION',\n",
       "  '# This will not be included in the student notebook because of BEGIN UNITTEST marker below.\\n\\n# Imitate the \\'import submission\\' environment with ad-hoc object.\\nfrom types import SimpleNamespace\\nsubmission = SimpleNamespace(printHello=printHello)\\n\\n# BEGIN UNITTEST\\nimport unittest\\n\\nimport sys\\nimport io\\nfrom contextlib import contextmanager\\nfrom io import StringIO\\n\\n@contextmanager\\ndef capture_output():\\n    capture_out, capture_err = StringIO(), StringIO()\\n    save_out, save_err = sys.stdout, sys.stderr\\n    try:\\n        sys.stdout, sys.stderr = capture_out, capture_err\\n        yield sys.stdout, sys.stderr\\n    finally:\\n        sys.stdout, sys.stderr = save_out, save_err\\n\\nclass HelloOutputTest(unittest.TestCase):\\n    def test_output(self):\\n        with capture_output() as (out, err):\\n            submission.printHello()\\n        self.assertEqual(err.getvalue(), \"\")\\n        self.assertEqual(out.getvalue(), \"Hello, world\\\\n\")\\n\\n# END UNITTEST\\n\\n# The parts after END UNITTEST are executed in the notebook environment, but not copied\\n# to the autograder scripts or to student notebooks.\\n\\n# TODO(salikh): Move this into a shared library and make that library installable via pip.\\nclass SummaryTestResult(unittest.TextTestResult):\\n    \"\"\"A small extension of TextTestResult that also collects a map of test statuses.\\n    \\n    \\n    result.results is a map from test name (string) to boolean: True(passed) or False(failed or error)\"\"\"\\n    \\n    separator1 = \\'=\\' * 70\\n    separator2 = \\'-\\' * 70\\n    \\n    def __init__(self, stream, descriptions, verbosity):\\n        super(unittest.TextTestResult, self).__init__(stream, descriptions, verbosity)\\n        # A map of test name to True(passed) or False(failed or error)\\n        self.results = {}\\n        # Copied from TextTestResult.\\n        self.stream = stream\\n        self.showAll = verbosity > 1\\n        self.dots = verbosity == 1\\n        self.descriptions = descriptions\\n\\n    def testName(self, test):\\n        \"\"\"A helper function to format the test as a human-readable string.\\n        \\n        The format is TestClassName.test_method. This is similar\\n        to TextTestResult.getDescription(test), but uses different format.\\n        getDescription: \\'test_one (__main__.HelloTest)\\'\\n        testName: \\'HelloTest.test_one\\'\\n        \"\"\"\\n        return unittest.util.strclass(test.__class__).replace(\\'__main__.\\', \\'\\') + \\'.\\' + test._testMethodName\\n        \\n    def getDescription(self, test):\\n        doc_first_line = test.shortDescription()\\n        if self.descriptions and doc_first_line:\\n            return \\'\\\\n\\'.join((str(test), doc_first_line))\\n        else:\\n            return str(test)\\n\\n    def startTest(self, test):\\n        super(unittest.TextTestResult, self).startTest(test)\\n        if self.showAll:\\n            self.stream.write(self.getDescription(test))\\n            self.stream.write(\" ... \")\\n            self.stream.flush()\\n\\n    def addSuccess(self, test):\\n        super(unittest.TextTestResult, self).addSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"ok\")\\n        elif self.dots:\\n            self.stream.write(\\'.\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = True\\n\\n    def addError(self, test, err):\\n        super(unittest.TextTestResult, self).addError(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"ERROR\")\\n        elif self.dots:\\n            self.stream.write(\\'E\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"FAIL\")\\n        elif self.dots:\\n            self.stream.write(\\'F\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addSkip(self, test, reason):\\n        super(unittest.TextTestResult, self).addSkip(test, reason)\\n        if self.showAll:\\n            self.stream.writeln(\"skipped {0!r}\".format(reason))\\n        elif self.dots:\\n            self.stream.write(\"s\")\\n            self.stream.flush()\\n\\n    def addExpectedFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addExpectedFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"expected failure\")\\n        elif self.dots:\\n            self.stream.write(\"x\")\\n            self.stream.flush()\\n\\n    def addUnexpectedSuccess(self, test):\\n        super(unittest.TextTestResult, self).addUnexpectedSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"unexpected success\")\\n        elif self.dots:\\n            self.stream.write(\"u\")\\n            self.stream.flush()\\n\\n    def printErrors(self):\\n        if self.dots or self.showAll:\\n            self.stream.writeln()\\n        self.printErrorList(\\'ERROR\\', self.errors)\\n        self.printErrorList(\\'FAIL\\', self.failures)\\n\\n    def printErrorList(self, flavour, errors):\\n        for test, err in errors:\\n            self.stream.writeln(self.separator1)\\n            self.stream.writeln(\"%s: %s\" % (flavour,self.getDescription(test)))\\n            self.stream.writeln(self.separator2)\\n            self.stream.writeln(\"%s\" % err)\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloOutputTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       "  'def hello(name):\\n    \"\"\" # BEGIN PROMPT\\n    # Please put your solution here:\\n    # return ...\\n    pass\\n    \"\"\" # END PROMPT\\n    # BEGIN SOLUTION\\n    return \"Hello, \" + name\\n    # END SOLUTION',\n",
       "  '# TEST\\nassert(hello(\"world\") == \"Hello, world\")',\n",
       "  '# The part before \"BEGIN UNITTEST\" -- preamble -- sets up the environment so that \\'submission.hello\\'\\n# is a function that we need to test. In the autograder worker environment, the preamble will be\\n# replaced with \\'import submission\\' with an assumption that the student\\'s solution will be written\\n# to the file \\'submission.py\\'.\\nsubmission = SimpleNamespace(hello=hello)\\n\\n# BEGIN UNITTEST\\n# The unit tests main part is contained between \"BEGIN UNITTEST\" and \"END UNITTEST\". It will be copied\\n# verbatim into the autograder directory, with an addition of \\'import submission;\\'\\n\\nimport unittest\\n\\nclass HelloTest(unittest.TestCase):\\n    def test_one(self):\\n        self.assertEqual(submission.hello(\"one\"), \"Hello, one\")\\n        \\n    def test_bad(self):\\n        self.assertEqual(submission.hello(\"bad\"), \"Hello, good\")\\n        \\n# END UNITTEST\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       "  '# BEGIN AUTOTEST\\n# The tests below test that the unit test suite above produces expected outcomes from\\n# TODO(salikh): Figure out the right syntax for autotests.\\ndef wrong_hello(name):\\n    return \"Bye, \" + name\\n\\nimport unittest\\n\\nsubmission.hello = wrong_hello\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors,  resultclass=SummaryTestResult).run(suite)\\n\\nprint(result.results)\\nassert(result.results[\\'HelloTest.test_bad\\'] == False)\\nassert(result.results[\\'HelloTest.test_one\\'] == False)',\n",
       "  \"get_ipython().run_cell_magic('submission', '', 'def syntax_error(name:\\\\n    return name\\\\n')\",\n",
       "  'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"my cell magic\"\"\"\\n    return cell\\n\\ndel lmagic, cmagic',\n",
       "  'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"my cell magic\"\"\"\\n    return cell\\n\\ndel submission',\n",
       "  '#%%submission\\ndef syntax_error(name:\\n    return name',\n",
       "  \"get_ipython().run_cell_magic('submission', '', 'def syntax_error(name:\\\\n    return name\\\\n')\",\n",
       "  'x = %%submission\\ndef syntax_error(name:\\n    return name',\n",
       "  'print(\"hello\")',\n",
       "  'print(\"bye bye\")',\n",
       "  'print(\"hey\", \"you\")',\n",
       "  'print(\"one\")\\nprint(\"two\")',\n",
       "  '\"\"\" # BEGIN PROMPT\\n   # ... put your program here\\n   pass\\n\"\"\" # END PROMPT\\ndef printHello():\\n    # BEGIN SOLUTION\\n    print(\"Hello, world\")\\n    # END SOLUTION',\n",
       "  '# This will not be included in the student notebook because of BEGIN UNITTEST marker below.\\n\\n# Imitate the \\'import submission\\' environment with ad-hoc object.\\nfrom types import SimpleNamespace\\nsubmission = SimpleNamespace(printHello=printHello)\\n\\n# BEGIN UNITTEST\\nimport unittest\\n\\nimport sys\\nimport io\\nfrom contextlib import contextmanager\\nfrom io import StringIO\\n\\n@contextmanager\\ndef capture_output():\\n    capture_out, capture_err = StringIO(), StringIO()\\n    save_out, save_err = sys.stdout, sys.stderr\\n    try:\\n        sys.stdout, sys.stderr = capture_out, capture_err\\n        yield sys.stdout, sys.stderr\\n    finally:\\n        sys.stdout, sys.stderr = save_out, save_err\\n\\nclass HelloOutputTest(unittest.TestCase):\\n    def test_output(self):\\n        with capture_output() as (out, err):\\n            submission.printHello()\\n        self.assertEqual(err.getvalue(), \"\")\\n        self.assertEqual(out.getvalue(), \"Hello, world\\\\n\")\\n\\n# END UNITTEST\\n\\n# The parts after END UNITTEST are executed in the notebook environment, but not copied\\n# to the autograder scripts or to student notebooks.\\n\\n# TODO(salikh): Move this into a shared library and make that library installable via pip.\\nclass SummaryTestResult(unittest.TextTestResult):\\n    \"\"\"A small extension of TextTestResult that also collects a map of test statuses.\\n    \\n    \\n    result.results is a map from test name (string) to boolean: True(passed) or False(failed or error)\"\"\"\\n    \\n    separator1 = \\'=\\' * 70\\n    separator2 = \\'-\\' * 70\\n    \\n    def __init__(self, stream, descriptions, verbosity):\\n        super(unittest.TextTestResult, self).__init__(stream, descriptions, verbosity)\\n        # A map of test name to True(passed) or False(failed or error)\\n        self.results = {}\\n        # Copied from TextTestResult.\\n        self.stream = stream\\n        self.showAll = verbosity > 1\\n        self.dots = verbosity == 1\\n        self.descriptions = descriptions\\n\\n    def testName(self, test):\\n        \"\"\"A helper function to format the test as a human-readable string.\\n        \\n        The format is TestClassName.test_method. This is similar\\n        to TextTestResult.getDescription(test), but uses different format.\\n        getDescription: \\'test_one (__main__.HelloTest)\\'\\n        testName: \\'HelloTest.test_one\\'\\n        \"\"\"\\n        return unittest.util.strclass(test.__class__).replace(\\'__main__.\\', \\'\\') + \\'.\\' + test._testMethodName\\n        \\n    def getDescription(self, test):\\n        doc_first_line = test.shortDescription()\\n        if self.descriptions and doc_first_line:\\n            return \\'\\\\n\\'.join((str(test), doc_first_line))\\n        else:\\n            return str(test)\\n\\n    def startTest(self, test):\\n        super(unittest.TextTestResult, self).startTest(test)\\n        if self.showAll:\\n            self.stream.write(self.getDescription(test))\\n            self.stream.write(\" ... \")\\n            self.stream.flush()\\n\\n    def addSuccess(self, test):\\n        super(unittest.TextTestResult, self).addSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"ok\")\\n        elif self.dots:\\n            self.stream.write(\\'.\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = True\\n\\n    def addError(self, test, err):\\n        super(unittest.TextTestResult, self).addError(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"ERROR\")\\n        elif self.dots:\\n            self.stream.write(\\'E\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"FAIL\")\\n        elif self.dots:\\n            self.stream.write(\\'F\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addSkip(self, test, reason):\\n        super(unittest.TextTestResult, self).addSkip(test, reason)\\n        if self.showAll:\\n            self.stream.writeln(\"skipped {0!r}\".format(reason))\\n        elif self.dots:\\n            self.stream.write(\"s\")\\n            self.stream.flush()\\n\\n    def addExpectedFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addExpectedFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"expected failure\")\\n        elif self.dots:\\n            self.stream.write(\"x\")\\n            self.stream.flush()\\n\\n    def addUnexpectedSuccess(self, test):\\n        super(unittest.TextTestResult, self).addUnexpectedSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"unexpected success\")\\n        elif self.dots:\\n            self.stream.write(\"u\")\\n            self.stream.flush()\\n\\n    def printErrors(self):\\n        if self.dots or self.showAll:\\n            self.stream.writeln()\\n        self.printErrorList(\\'ERROR\\', self.errors)\\n        self.printErrorList(\\'FAIL\\', self.failures)\\n\\n    def printErrorList(self, flavour, errors):\\n        for test, err in errors:\\n            self.stream.writeln(self.separator1)\\n            self.stream.writeln(\"%s: %s\" % (flavour,self.getDescription(test)))\\n            self.stream.writeln(self.separator2)\\n            self.stream.writeln(\"%s\" % err)\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloOutputTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       "  'def hello(name):\\n    \"\"\" # BEGIN PROMPT\\n    # Please put your solution here:\\n    # return ...\\n    pass\\n    \"\"\" # END PROMPT\\n    # BEGIN SOLUTION\\n    return \"Hello, \" + name\\n    # END SOLUTION',\n",
       "  '# TEST\\nassert(hello(\"world\") == \"Hello, world\")',\n",
       "  '# The part before \"BEGIN UNITTEST\" -- preamble -- sets up the environment so that \\'submission.hello\\'\\n# is a function that we need to test. In the autograder worker environment, the preamble will be\\n# replaced with \\'import submission\\' with an assumption that the student\\'s solution will be written\\n# to the file \\'submission.py\\'.\\nsubmission = SimpleNamespace(hello=hello)\\n\\n# BEGIN UNITTEST\\n# The unit tests main part is contained between \"BEGIN UNITTEST\" and \"END UNITTEST\". It will be copied\\n# verbatim into the autograder directory, with an addition of \\'import submission;\\'\\n\\nimport unittest\\n\\nclass HelloTest(unittest.TestCase):\\n    def test_one(self):\\n        self.assertEqual(submission.hello(\"one\"), \"Hello, one\")\\n        \\n    def test_bad(self):\\n        self.assertEqual(submission.hello(\"bad\"), \"Hello, good\")\\n        \\n# END UNITTEST\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       "  '# BEGIN AUTOTEST\\n# The tests below test that the unit test suite above produces expected outcomes from\\n# TODO(salikh): Figure out the right syntax for autotests.\\ndef wrong_hello(name):\\n    return \"Bye, \" + name\\n\\nimport unittest\\n\\nsubmission.hello = wrong_hello\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors,  resultclass=SummaryTestResult).run(suite)\\n\\nprint(result.results)\\nassert(result.results[\\'HelloTest.test_bad\\'] == False)\\nassert(result.results[\\'HelloTest.test_one\\'] == False)',\n",
       "  'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"my cell magic\"\"\"\\n    return cell\\n\\ndel submission',\n",
       "  \"get_ipython().run_cell_magic('submission', '', 'def syntax_error(name:\\\\n    return name\\\\n')\",\n",
       "  \"result = get_ipython().run_line_magic('autotest(HelloTest)', '')\\nassert(result['HelloTest.test_bad'] == False)\",\n",
       "  'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"A magic to mark a textual submission, possibly incorrect and unparseable.\"\"\"\\n    return cell\\n\\n@register_line_magic\\ndef autotest(line):\\n    \"\"\"A magic to run an auto test: run previously defined unit tests with a submission just given.\"\"\"\\n    return eval(line)\\n\\ndel submission, autotest',\n",
       "  \"get_ipython().run_cell_magic('submission', '', 'def syntax_error(name:\\\\n    return name\\\\n')\",\n",
       "  \"result = get_ipython().run_line_magic('autotest(HelloTest)', '')\\nassert(result['HelloTest.test_bad'] == False)\",\n",
       "  \"get_ipython().run_cell_magic('submission', '', 'def syntax_error(name:\\\\n    return name\\\\n')\",\n",
       "  \"result = get_ipython().run_line_magic('autotest', 'HelloTest')\\nassert(result['HelloTest.test_bad'] == False)\",\n",
       "  \"result = get_ipython().run_line_magic('autotest', 'HelloTest')\\nresult\\n#assert(result['HelloTest.test_bad'] == False)\",\n",
       "  \"result = get_ipython().run_line_magic('autotest', 'HelloTest')\\nresult\\n#assert(result['HelloTest.test_bad'] == False)\",\n",
       "  'print(\"hello\")',\n",
       "  'print(\"bye bye\")',\n",
       "  'print(\"hey\", \"you\")',\n",
       "  'print(\"one\")\\nprint(\"two\")',\n",
       "  '\"\"\" # BEGIN PROMPT\\n   # ... put your program here\\n   pass\\n\"\"\" # END PROMPT\\ndef printHello():\\n    # BEGIN SOLUTION\\n    print(\"Hello, world\")\\n    # END SOLUTION',\n",
       "  '# This will not be included in the student notebook because of BEGIN UNITTEST marker below.\\n\\n# Imitate the \\'import submission\\' environment with ad-hoc object.\\nfrom types import SimpleNamespace\\nsubmission = SimpleNamespace(printHello=printHello)\\n\\n# BEGIN UNITTEST\\nimport unittest\\n\\nimport sys\\nimport io\\nfrom contextlib import contextmanager\\nfrom io import StringIO\\n\\n@contextmanager\\ndef capture_output():\\n    capture_out, capture_err = StringIO(), StringIO()\\n    save_out, save_err = sys.stdout, sys.stderr\\n    try:\\n        sys.stdout, sys.stderr = capture_out, capture_err\\n        yield sys.stdout, sys.stderr\\n    finally:\\n        sys.stdout, sys.stderr = save_out, save_err\\n\\nclass HelloOutputTest(unittest.TestCase):\\n    def test_output(self):\\n        with capture_output() as (out, err):\\n            submission.printHello()\\n        self.assertEqual(err.getvalue(), \"\")\\n        self.assertEqual(out.getvalue(), \"Hello, world\\\\n\")\\n\\n# END UNITTEST\\n\\n# The parts after END UNITTEST are executed in the notebook environment, but not copied\\n# to the autograder scripts or to student notebooks.\\n\\n# TODO(salikh): Move this into a shared library and make that library installable via pip.\\nclass SummaryTestResult(unittest.TextTestResult):\\n    \"\"\"A small extension of TextTestResult that also collects a map of test statuses.\\n    \\n    \\n    result.results is a map from test name (string) to boolean: True(passed) or False(failed or error)\"\"\"\\n    \\n    separator1 = \\'=\\' * 70\\n    separator2 = \\'-\\' * 70\\n    \\n    def __init__(self, stream, descriptions, verbosity):\\n        super(unittest.TextTestResult, self).__init__(stream, descriptions, verbosity)\\n        # A map of test name to True(passed) or False(failed or error)\\n        self.results = {}\\n        # Copied from TextTestResult.\\n        self.stream = stream\\n        self.showAll = verbosity > 1\\n        self.dots = verbosity == 1\\n        self.descriptions = descriptions\\n\\n    def testName(self, test):\\n        \"\"\"A helper function to format the test as a human-readable string.\\n        \\n        The format is TestClassName.test_method. This is similar\\n        to TextTestResult.getDescription(test), but uses different format.\\n        getDescription: \\'test_one (__main__.HelloTest)\\'\\n        testName: \\'HelloTest.test_one\\'\\n        \"\"\"\\n        return unittest.util.strclass(test.__class__).replace(\\'__main__.\\', \\'\\') + \\'.\\' + test._testMethodName\\n        \\n    def getDescription(self, test):\\n        doc_first_line = test.shortDescription()\\n        if self.descriptions and doc_first_line:\\n            return \\'\\\\n\\'.join((str(test), doc_first_line))\\n        else:\\n            return str(test)\\n\\n    def startTest(self, test):\\n        super(unittest.TextTestResult, self).startTest(test)\\n        if self.showAll:\\n            self.stream.write(self.getDescription(test))\\n            self.stream.write(\" ... \")\\n            self.stream.flush()\\n\\n    def addSuccess(self, test):\\n        super(unittest.TextTestResult, self).addSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"ok\")\\n        elif self.dots:\\n            self.stream.write(\\'.\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = True\\n\\n    def addError(self, test, err):\\n        super(unittest.TextTestResult, self).addError(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"ERROR\")\\n        elif self.dots:\\n            self.stream.write(\\'E\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"FAIL\")\\n        elif self.dots:\\n            self.stream.write(\\'F\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addSkip(self, test, reason):\\n        super(unittest.TextTestResult, self).addSkip(test, reason)\\n        if self.showAll:\\n            self.stream.writeln(\"skipped {0!r}\".format(reason))\\n        elif self.dots:\\n            self.stream.write(\"s\")\\n            self.stream.flush()\\n\\n    def addExpectedFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addExpectedFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"expected failure\")\\n        elif self.dots:\\n            self.stream.write(\"x\")\\n            self.stream.flush()\\n\\n    def addUnexpectedSuccess(self, test):\\n        super(unittest.TextTestResult, self).addUnexpectedSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"unexpected success\")\\n        elif self.dots:\\n            self.stream.write(\"u\")\\n            self.stream.flush()\\n\\n    def printErrors(self):\\n        if self.dots or self.showAll:\\n            self.stream.writeln()\\n        self.printErrorList(\\'ERROR\\', self.errors)\\n        self.printErrorList(\\'FAIL\\', self.failures)\\n\\n    def printErrorList(self, flavour, errors):\\n        for test, err in errors:\\n            self.stream.writeln(self.separator1)\\n            self.stream.writeln(\"%s: %s\" % (flavour,self.getDescription(test)))\\n            self.stream.writeln(self.separator2)\\n            self.stream.writeln(\"%s\" % err)\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloOutputTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       "  'def hello(name):\\n    \"\"\" # BEGIN PROMPT\\n    # Please put your solution here:\\n    # return ...\\n    pass\\n    \"\"\" # END PROMPT\\n    # BEGIN SOLUTION\\n    return \"Hello, \" + name\\n    # END SOLUTION',\n",
       "  '# TEST\\nassert(hello(\"world\") == \"Hello, world\")',\n",
       "  '# The part before \"BEGIN UNITTEST\" -- preamble -- sets up the environment so that \\'submission.hello\\'\\n# is a function that we need to test. In the autograder worker environment, the preamble will be\\n# replaced with \\'import submission\\' with an assumption that the student\\'s solution will be written\\n# to the file \\'submission.py\\'.\\nsubmission = SimpleNamespace(hello=hello)\\n\\n# BEGIN UNITTEST\\n# The unit tests main part is contained between \"BEGIN UNITTEST\" and \"END UNITTEST\". It will be copied\\n# verbatim into the autograder directory, with an addition of \\'import submission;\\'\\n\\nimport unittest\\n\\nclass HelloTest(unittest.TestCase):\\n    def test_one(self):\\n        self.assertEqual(submission.hello(\"one\"), \"Hello, one\")\\n        \\n    def test_bad(self):\\n        self.assertEqual(submission.hello(\"bad\"), \"Hello, good\")\\n        \\n# END UNITTEST\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       "  '# BEGIN AUTOTEST\\n# The tests below test that the unit test suite above produces expected outcomes from\\n# TODO(salikh): Figure out the right syntax for autotests.\\ndef wrong_hello(name):\\n    return \"Bye, \" + name\\n\\nimport unittest\\n\\nsubmission.hello = wrong_hello\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors,  resultclass=SummaryTestResult).run(suite)\\n\\nprint(result.results)\\nassert(result.results[\\'HelloTest.test_bad\\'] == False)\\nassert(result.results[\\'HelloTest.test_one\\'] == False)',\n",
       "  'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"A magic to mark a textual submission, possibly incorrect and unparseable.\"\"\"\\n    return cell\\n\\n@register_line_magic\\ndef autotest(line):\\n    \"\"\"A magic to run an auto test: run previously defined unit tests with a submission just given.\"\"\"\\n    return eval(line)\\n\\ndel submission, autotest',\n",
       "  \"get_ipython().run_cell_magic('submission', '', 'def syntax_error(name:\\\\n    return name\\\\n')\",\n",
       "  \"result = get_ipython().run_line_magic('autotest', 'HelloTest')\\nresult\\n#assert(result['HelloTest.test_bad'] == False)\",\n",
       "  'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_line_magic\\ndef lmagic(line):\\n    \"my line magic\"\\n    return line\\n\\n@register_cell_magic\\ndef cmagic(line, cell):\\n    \"my cell magic\"\\n    return cell\\n\\ndel lmagic, cmagic',\n",
       "  'x = get_ipython().run_line_magic(\\'lmagic\\', \\'a b c\\')\\nprint(\"Hello, \" +x)',\n",
       "  \"get_ipython().run_cell_magic('cmagic', '', 'my cell magic\\\\nasfd\\\\n')\",\n",
       "  'vars()',\n",
       "  'from IPython.core.magic import (Magics, magics_class, line_magic,\\n                                cell_magic, line_cell_magic)\\n\\n# The class MUST call this class decorator at creation time\\n@magics_class\\nclass MyMagics(Magics):\\n\\n    @line_magic\\n    def lmagic(self, line):\\n        \"my line magic\"\\n        print(\"Full access to the main IPython object:\", self.shell)\\n        print(\"Variables in the user namespace:\", list(self.shell.user_ns.keys()))\\n        return line\\n\\n    @cell_magic\\n    def cmagic(self, line, cell):\\n        \"my cell magic\"\\n        return line, cell\\n\\n    @line_cell_magic\\n    def lcmagic(self, line, cell=None):\\n        \"Magic that works both as %lcmagic and as %%lcmagic\"\\n        if cell is None:\\n            print(\"Called as line magic\")\\n            return line\\n        else:\\n            print(\"Called as cell magic\")\\n            return line, cell\\n        \\nip = get_ipython()\\nip.register_magics(MyMagics)',\n",
       "  \"get_ipython().run_line_magic('lmagic', 'ab cd ef')\",\n",
       "  'print(\"hello\")',\n",
       "  'print(\"bye bye\")',\n",
       "  'print(\"hey\", \"you\")',\n",
       "  'print(\"one\")\\nprint(\"two\")',\n",
       "  '\"\"\" # BEGIN PROMPT\\n   # ... put your program here\\n   pass\\n\"\"\" # END PROMPT\\ndef printHello():\\n    # BEGIN SOLUTION\\n    print(\"Hello, world\")\\n    # END SOLUTION',\n",
       "  '# This will not be included in the student notebook because of BEGIN UNITTEST marker below.\\n\\n# Imitate the \\'import submission\\' environment with ad-hoc object.\\nfrom types import SimpleNamespace\\nsubmission = SimpleNamespace(printHello=printHello)\\n\\n# BEGIN UNITTEST\\nimport unittest\\n\\nimport sys\\nimport io\\nfrom contextlib import contextmanager\\nfrom io import StringIO\\n\\n@contextmanager\\ndef capture_output():\\n    capture_out, capture_err = StringIO(), StringIO()\\n    save_out, save_err = sys.stdout, sys.stderr\\n    try:\\n        sys.stdout, sys.stderr = capture_out, capture_err\\n        yield sys.stdout, sys.stderr\\n    finally:\\n        sys.stdout, sys.stderr = save_out, save_err\\n\\nclass HelloOutputTest(unittest.TestCase):\\n    def test_output(self):\\n        with capture_output() as (out, err):\\n            submission.printHello()\\n        self.assertEqual(err.getvalue(), \"\")\\n        self.assertEqual(out.getvalue(), \"Hello, world\\\\n\")\\n\\n# END UNITTEST\\n\\n# The parts after END UNITTEST are executed in the notebook environment, but not copied\\n# to the autograder scripts or to student notebooks.\\n\\n# TODO(salikh): Move this into a shared library and make that library installable via pip.\\nclass SummaryTestResult(unittest.TextTestResult):\\n    \"\"\"A small extension of TextTestResult that also collects a map of test statuses.\\n    \\n    \\n    result.results is a map from test name (string) to boolean: True(passed) or False(failed or error)\"\"\"\\n    \\n    separator1 = \\'=\\' * 70\\n    separator2 = \\'-\\' * 70\\n    \\n    def __init__(self, stream, descriptions, verbosity):\\n        super(unittest.TextTestResult, self).__init__(stream, descriptions, verbosity)\\n        # A map of test name to True(passed) or False(failed or error)\\n        self.results = {}\\n        # Copied from TextTestResult.\\n        self.stream = stream\\n        self.showAll = verbosity > 1\\n        self.dots = verbosity == 1\\n        self.descriptions = descriptions\\n\\n    def testName(self, test):\\n        \"\"\"A helper function to format the test as a human-readable string.\\n        \\n        The format is TestClassName.test_method. This is similar\\n        to TextTestResult.getDescription(test), but uses different format.\\n        getDescription: \\'test_one (__main__.HelloTest)\\'\\n        testName: \\'HelloTest.test_one\\'\\n        \"\"\"\\n        return unittest.util.strclass(test.__class__).replace(\\'__main__.\\', \\'\\') + \\'.\\' + test._testMethodName\\n        \\n    def getDescription(self, test):\\n        doc_first_line = test.shortDescription()\\n        if self.descriptions and doc_first_line:\\n            return \\'\\\\n\\'.join((str(test), doc_first_line))\\n        else:\\n            return str(test)\\n\\n    def startTest(self, test):\\n        super(unittest.TextTestResult, self).startTest(test)\\n        if self.showAll:\\n            self.stream.write(self.getDescription(test))\\n            self.stream.write(\" ... \")\\n            self.stream.flush()\\n\\n    def addSuccess(self, test):\\n        super(unittest.TextTestResult, self).addSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"ok\")\\n        elif self.dots:\\n            self.stream.write(\\'.\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = True\\n\\n    def addError(self, test, err):\\n        super(unittest.TextTestResult, self).addError(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"ERROR\")\\n        elif self.dots:\\n            self.stream.write(\\'E\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"FAIL\")\\n        elif self.dots:\\n            self.stream.write(\\'F\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addSkip(self, test, reason):\\n        super(unittest.TextTestResult, self).addSkip(test, reason)\\n        if self.showAll:\\n            self.stream.writeln(\"skipped {0!r}\".format(reason))\\n        elif self.dots:\\n            self.stream.write(\"s\")\\n            self.stream.flush()\\n\\n    def addExpectedFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addExpectedFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"expected failure\")\\n        elif self.dots:\\n            self.stream.write(\"x\")\\n            self.stream.flush()\\n\\n    def addUnexpectedSuccess(self, test):\\n        super(unittest.TextTestResult, self).addUnexpectedSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"unexpected success\")\\n        elif self.dots:\\n            self.stream.write(\"u\")\\n            self.stream.flush()\\n\\n    def printErrors(self):\\n        if self.dots or self.showAll:\\n            self.stream.writeln()\\n        self.printErrorList(\\'ERROR\\', self.errors)\\n        self.printErrorList(\\'FAIL\\', self.failures)\\n\\n    def printErrorList(self, flavour, errors):\\n        for test, err in errors:\\n            self.stream.writeln(self.separator1)\\n            self.stream.writeln(\"%s: %s\" % (flavour,self.getDescription(test)))\\n            self.stream.writeln(self.separator2)\\n            self.stream.writeln(\"%s\" % err)\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloOutputTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       "  'def hello(name):\\n    \"\"\" # BEGIN PROMPT\\n    # Please put your solution here:\\n    # return ...\\n    pass\\n    \"\"\" # END PROMPT\\n    # BEGIN SOLUTION\\n    return \"Hello, \" + name\\n    # END SOLUTION',\n",
       "  '# TEST\\nassert(hello(\"world\") == \"Hello, world\")',\n",
       "  '# The part before \"BEGIN UNITTEST\" -- preamble -- sets up the environment so that \\'submission.hello\\'\\n# is a function that we need to test. In the autograder worker environment, the preamble will be\\n# replaced with \\'import submission\\' with an assumption that the student\\'s solution will be written\\n# to the file \\'submission.py\\'.\\nsubmission = SimpleNamespace(hello=hello)\\n\\n# BEGIN UNITTEST\\n# The unit tests main part is contained between \"BEGIN UNITTEST\" and \"END UNITTEST\". It will be copied\\n# verbatim into the autograder directory, with an addition of \\'import submission;\\'\\n\\nimport unittest\\n\\nclass HelloTest(unittest.TestCase):\\n    def test_one(self):\\n        self.assertEqual(submission.hello(\"one\"), \"Hello, one\")\\n        \\n    def test_bad(self):\\n        self.assertEqual(submission.hello(\"bad\"), \"Hello, good\")\\n        \\n# END UNITTEST\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       "  '# BEGIN AUTOTEST\\n# The tests below test that the unit test suite above produces expected outcomes from\\n# TODO(salikh): Figure out the right syntax for autotests.\\ndef wrong_hello(name):\\n    return \"Bye, \" + name\\n\\nimport unittest\\n\\nsubmission.hello = wrong_hello\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors,  resultclass=SummaryTestResult).run(suite)\\n\\nprint(result.results)\\nassert(result.results[\\'HelloTest.test_bad\\'] == False)\\nassert(result.results[\\'HelloTest.test_one\\'] == False)',\n",
       "  'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"A magic to mark a textual submission, possibly incorrect and unparseable.\"\"\"\\n    return cell\\n\\n@register_line_magic\\ndef autotest(line):\\n    \"\"\"A magic to run an auto test: run previously defined unit tests with a submission just given.\"\"\"\\n    return eval(line)\\n\\ndel submission, autotest',\n",
       "  \"get_ipython().run_cell_magic('submission', '', 'def syntax_error(name:\\\\n    return name\\\\n')\",\n",
       "  \"result = get_ipython().run_line_magic('autotest', 'HelloTest')\\nresult\\n#assert(result['HelloTest.test_bad'] == False)\",\n",
       "  'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_line_magic\\ndef lmagic(line):\\n    \"my line magic\"\\n    return line\\n\\n@register_cell_magic\\ndef cmagic(line, cell):\\n    \"my cell magic\"\\n    return cell\\n\\ndel lmagic, cmagic',\n",
       "  'x = get_ipython().run_line_magic(\\'lmagic\\', \\'a b c\\')\\nprint(\"Hello, \" +x)',\n",
       "  \"get_ipython().run_cell_magic('cmagic', '', 'my cell magic\\\\nasfd\\\\n')\",\n",
       "  'vars()'],\n",
       " '_oh': {15: 'def syntax_error(name:\\n    return name\\n',\n",
       "  28: 'def syntax_error(name:\\n    return name\\n',\n",
       "  31: 'def syntax_error(name:\\n    return name\\n',\n",
       "  33: 'def syntax_error(name:\\n    return name\\n',\n",
       "  35: __main__.HelloTest,\n",
       "  36: __main__.HelloTest,\n",
       "  48: 'def syntax_error(name:\\n    return name\\n',\n",
       "  49: __main__.HelloTest,\n",
       "  52: 'my cell magic\\nasfd\\n',\n",
       "  53: {...},\n",
       "  55: 'ab cd ef',\n",
       "  67: 'def syntax_error(name:\\n    return name\\n',\n",
       "  68: __main__.HelloTest,\n",
       "  71: 'my cell magic\\nasfd\\n'},\n",
       " '_dh': ['/home/salikh/uot/prog-edu-assistant/exercises'],\n",
       " 'In': ['',\n",
       "  'print(\"hello\")',\n",
       "  'print(\"bye bye\")',\n",
       "  'print(\"hey\", \"you\")',\n",
       "  'print(\"one\")\\nprint(\"two\")',\n",
       "  '\"\"\" # BEGIN PROMPT\\n   # ... put your program here\\n   pass\\n\"\"\" # END PROMPT\\ndef printHello():\\n    # BEGIN SOLUTION\\n    print(\"Hello, world\")\\n    # END SOLUTION',\n",
       "  '# This will not be included in the student notebook because of BEGIN UNITTEST marker below.\\n\\n# Imitate the \\'import submission\\' environment with ad-hoc object.\\nfrom types import SimpleNamespace\\nsubmission = SimpleNamespace(printHello=printHello)\\n\\n# BEGIN UNITTEST\\nimport unittest\\n\\nimport sys\\nimport io\\nfrom contextlib import contextmanager\\nfrom io import StringIO\\n\\n@contextmanager\\ndef capture_output():\\n    capture_out, capture_err = StringIO(), StringIO()\\n    save_out, save_err = sys.stdout, sys.stderr\\n    try:\\n        sys.stdout, sys.stderr = capture_out, capture_err\\n        yield sys.stdout, sys.stderr\\n    finally:\\n        sys.stdout, sys.stderr = save_out, save_err\\n\\nclass HelloOutputTest(unittest.TestCase):\\n    def test_output(self):\\n        with capture_output() as (out, err):\\n            submission.printHello()\\n        self.assertEqual(err.getvalue(), \"\")\\n        self.assertEqual(out.getvalue(), \"Hello, world\\\\n\")\\n\\n# END UNITTEST\\n\\n# The parts after END UNITTEST are executed in the notebook environment, but not copied\\n# to the autograder scripts or to student notebooks.\\n\\n# TODO(salikh): Move this into a shared library and make that library installable via pip.\\nclass SummaryTestResult(unittest.TextTestResult):\\n    \"\"\"A small extension of TextTestResult that also collects a map of test statuses.\\n    \\n    \\n    result.results is a map from test name (string) to boolean: True(passed) or False(failed or error)\"\"\"\\n    \\n    separator1 = \\'=\\' * 70\\n    separator2 = \\'-\\' * 70\\n    \\n    def __init__(self, stream, descriptions, verbosity):\\n        super(unittest.TextTestResult, self).__init__(stream, descriptions, verbosity)\\n        # A map of test name to True(passed) or False(failed or error)\\n        self.results = {}\\n        # Copied from TextTestResult.\\n        self.stream = stream\\n        self.showAll = verbosity > 1\\n        self.dots = verbosity == 1\\n        self.descriptions = descriptions\\n\\n    def testName(self, test):\\n        \"\"\"A helper function to format the test as a human-readable string.\\n        \\n        The format is TestClassName.test_method. This is similar\\n        to TextTestResult.getDescription(test), but uses different format.\\n        getDescription: \\'test_one (__main__.HelloTest)\\'\\n        testName: \\'HelloTest.test_one\\'\\n        \"\"\"\\n        return unittest.util.strclass(test.__class__).replace(\\'__main__.\\', \\'\\') + \\'.\\' + test._testMethodName\\n        \\n    def getDescription(self, test):\\n        doc_first_line = test.shortDescription()\\n        if self.descriptions and doc_first_line:\\n            return \\'\\\\n\\'.join((str(test), doc_first_line))\\n        else:\\n            return str(test)\\n\\n    def startTest(self, test):\\n        super(unittest.TextTestResult, self).startTest(test)\\n        if self.showAll:\\n            self.stream.write(self.getDescription(test))\\n            self.stream.write(\" ... \")\\n            self.stream.flush()\\n\\n    def addSuccess(self, test):\\n        super(unittest.TextTestResult, self).addSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"ok\")\\n        elif self.dots:\\n            self.stream.write(\\'.\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = True\\n\\n    def addError(self, test, err):\\n        super(unittest.TextTestResult, self).addError(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"ERROR\")\\n        elif self.dots:\\n            self.stream.write(\\'E\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"FAIL\")\\n        elif self.dots:\\n            self.stream.write(\\'F\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addSkip(self, test, reason):\\n        super(unittest.TextTestResult, self).addSkip(test, reason)\\n        if self.showAll:\\n            self.stream.writeln(\"skipped {0!r}\".format(reason))\\n        elif self.dots:\\n            self.stream.write(\"s\")\\n            self.stream.flush()\\n\\n    def addExpectedFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addExpectedFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"expected failure\")\\n        elif self.dots:\\n            self.stream.write(\"x\")\\n            self.stream.flush()\\n\\n    def addUnexpectedSuccess(self, test):\\n        super(unittest.TextTestResult, self).addUnexpectedSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"unexpected success\")\\n        elif self.dots:\\n            self.stream.write(\"u\")\\n            self.stream.flush()\\n\\n    def printErrors(self):\\n        if self.dots or self.showAll:\\n            self.stream.writeln()\\n        self.printErrorList(\\'ERROR\\', self.errors)\\n        self.printErrorList(\\'FAIL\\', self.failures)\\n\\n    def printErrorList(self, flavour, errors):\\n        for test, err in errors:\\n            self.stream.writeln(self.separator1)\\n            self.stream.writeln(\"%s: %s\" % (flavour,self.getDescription(test)))\\n            self.stream.writeln(self.separator2)\\n            self.stream.writeln(\"%s\" % err)\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloOutputTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       "  'def hello(name):\\n    \"\"\" # BEGIN PROMPT\\n    # Please put your solution here:\\n    # return ...\\n    pass\\n    \"\"\" # END PROMPT\\n    # BEGIN SOLUTION\\n    return \"Hello, \" + name\\n    # END SOLUTION',\n",
       "  '# TEST\\nassert(hello(\"world\") == \"Hello, world\")',\n",
       "  '# The part before \"BEGIN UNITTEST\" -- preamble -- sets up the environment so that \\'submission.hello\\'\\n# is a function that we need to test. In the autograder worker environment, the preamble will be\\n# replaced with \\'import submission\\' with an assumption that the student\\'s solution will be written\\n# to the file \\'submission.py\\'.\\nsubmission = SimpleNamespace(hello=hello)\\n\\n# BEGIN UNITTEST\\n# The unit tests main part is contained between \"BEGIN UNITTEST\" and \"END UNITTEST\". It will be copied\\n# verbatim into the autograder directory, with an addition of \\'import submission;\\'\\n\\nimport unittest\\n\\nclass HelloTest(unittest.TestCase):\\n    def test_one(self):\\n        self.assertEqual(submission.hello(\"one\"), \"Hello, one\")\\n        \\n    def test_bad(self):\\n        self.assertEqual(submission.hello(\"bad\"), \"Hello, good\")\\n        \\n# END UNITTEST\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       "  '# BEGIN AUTOTEST\\n# The tests below test that the unit test suite above produces expected outcomes from\\n# TODO(salikh): Figure out the right syntax for autotests.\\ndef wrong_hello(name):\\n    return \"Bye, \" + name\\n\\nimport unittest\\n\\nsubmission.hello = wrong_hello\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors,  resultclass=SummaryTestResult).run(suite)\\n\\nprint(result.results)\\nassert(result.results[\\'HelloTest.test_bad\\'] == False)\\nassert(result.results[\\'HelloTest.test_one\\'] == False)',\n",
       "  \"get_ipython().run_cell_magic('submission', '', 'def syntax_error(name:\\\\n    return name\\\\n')\",\n",
       "  'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"my cell magic\"\"\"\\n    return cell\\n\\ndel lmagic, cmagic',\n",
       "  'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"my cell magic\"\"\"\\n    return cell\\n\\ndel submission',\n",
       "  '#%%submission\\ndef syntax_error(name:\\n    return name',\n",
       "  \"get_ipython().run_cell_magic('submission', '', 'def syntax_error(name:\\\\n    return name\\\\n')\",\n",
       "  'x = %%submission\\ndef syntax_error(name:\\n    return name',\n",
       "  'print(\"hello\")',\n",
       "  'print(\"bye bye\")',\n",
       "  'print(\"hey\", \"you\")',\n",
       "  'print(\"one\")\\nprint(\"two\")',\n",
       "  '\"\"\" # BEGIN PROMPT\\n   # ... put your program here\\n   pass\\n\"\"\" # END PROMPT\\ndef printHello():\\n    # BEGIN SOLUTION\\n    print(\"Hello, world\")\\n    # END SOLUTION',\n",
       "  '# This will not be included in the student notebook because of BEGIN UNITTEST marker below.\\n\\n# Imitate the \\'import submission\\' environment with ad-hoc object.\\nfrom types import SimpleNamespace\\nsubmission = SimpleNamespace(printHello=printHello)\\n\\n# BEGIN UNITTEST\\nimport unittest\\n\\nimport sys\\nimport io\\nfrom contextlib import contextmanager\\nfrom io import StringIO\\n\\n@contextmanager\\ndef capture_output():\\n    capture_out, capture_err = StringIO(), StringIO()\\n    save_out, save_err = sys.stdout, sys.stderr\\n    try:\\n        sys.stdout, sys.stderr = capture_out, capture_err\\n        yield sys.stdout, sys.stderr\\n    finally:\\n        sys.stdout, sys.stderr = save_out, save_err\\n\\nclass HelloOutputTest(unittest.TestCase):\\n    def test_output(self):\\n        with capture_output() as (out, err):\\n            submission.printHello()\\n        self.assertEqual(err.getvalue(), \"\")\\n        self.assertEqual(out.getvalue(), \"Hello, world\\\\n\")\\n\\n# END UNITTEST\\n\\n# The parts after END UNITTEST are executed in the notebook environment, but not copied\\n# to the autograder scripts or to student notebooks.\\n\\n# TODO(salikh): Move this into a shared library and make that library installable via pip.\\nclass SummaryTestResult(unittest.TextTestResult):\\n    \"\"\"A small extension of TextTestResult that also collects a map of test statuses.\\n    \\n    \\n    result.results is a map from test name (string) to boolean: True(passed) or False(failed or error)\"\"\"\\n    \\n    separator1 = \\'=\\' * 70\\n    separator2 = \\'-\\' * 70\\n    \\n    def __init__(self, stream, descriptions, verbosity):\\n        super(unittest.TextTestResult, self).__init__(stream, descriptions, verbosity)\\n        # A map of test name to True(passed) or False(failed or error)\\n        self.results = {}\\n        # Copied from TextTestResult.\\n        self.stream = stream\\n        self.showAll = verbosity > 1\\n        self.dots = verbosity == 1\\n        self.descriptions = descriptions\\n\\n    def testName(self, test):\\n        \"\"\"A helper function to format the test as a human-readable string.\\n        \\n        The format is TestClassName.test_method. This is similar\\n        to TextTestResult.getDescription(test), but uses different format.\\n        getDescription: \\'test_one (__main__.HelloTest)\\'\\n        testName: \\'HelloTest.test_one\\'\\n        \"\"\"\\n        return unittest.util.strclass(test.__class__).replace(\\'__main__.\\', \\'\\') + \\'.\\' + test._testMethodName\\n        \\n    def getDescription(self, test):\\n        doc_first_line = test.shortDescription()\\n        if self.descriptions and doc_first_line:\\n            return \\'\\\\n\\'.join((str(test), doc_first_line))\\n        else:\\n            return str(test)\\n\\n    def startTest(self, test):\\n        super(unittest.TextTestResult, self).startTest(test)\\n        if self.showAll:\\n            self.stream.write(self.getDescription(test))\\n            self.stream.write(\" ... \")\\n            self.stream.flush()\\n\\n    def addSuccess(self, test):\\n        super(unittest.TextTestResult, self).addSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"ok\")\\n        elif self.dots:\\n            self.stream.write(\\'.\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = True\\n\\n    def addError(self, test, err):\\n        super(unittest.TextTestResult, self).addError(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"ERROR\")\\n        elif self.dots:\\n            self.stream.write(\\'E\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"FAIL\")\\n        elif self.dots:\\n            self.stream.write(\\'F\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addSkip(self, test, reason):\\n        super(unittest.TextTestResult, self).addSkip(test, reason)\\n        if self.showAll:\\n            self.stream.writeln(\"skipped {0!r}\".format(reason))\\n        elif self.dots:\\n            self.stream.write(\"s\")\\n            self.stream.flush()\\n\\n    def addExpectedFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addExpectedFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"expected failure\")\\n        elif self.dots:\\n            self.stream.write(\"x\")\\n            self.stream.flush()\\n\\n    def addUnexpectedSuccess(self, test):\\n        super(unittest.TextTestResult, self).addUnexpectedSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"unexpected success\")\\n        elif self.dots:\\n            self.stream.write(\"u\")\\n            self.stream.flush()\\n\\n    def printErrors(self):\\n        if self.dots or self.showAll:\\n            self.stream.writeln()\\n        self.printErrorList(\\'ERROR\\', self.errors)\\n        self.printErrorList(\\'FAIL\\', self.failures)\\n\\n    def printErrorList(self, flavour, errors):\\n        for test, err in errors:\\n            self.stream.writeln(self.separator1)\\n            self.stream.writeln(\"%s: %s\" % (flavour,self.getDescription(test)))\\n            self.stream.writeln(self.separator2)\\n            self.stream.writeln(\"%s\" % err)\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloOutputTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       "  'def hello(name):\\n    \"\"\" # BEGIN PROMPT\\n    # Please put your solution here:\\n    # return ...\\n    pass\\n    \"\"\" # END PROMPT\\n    # BEGIN SOLUTION\\n    return \"Hello, \" + name\\n    # END SOLUTION',\n",
       "  '# TEST\\nassert(hello(\"world\") == \"Hello, world\")',\n",
       "  '# The part before \"BEGIN UNITTEST\" -- preamble -- sets up the environment so that \\'submission.hello\\'\\n# is a function that we need to test. In the autograder worker environment, the preamble will be\\n# replaced with \\'import submission\\' with an assumption that the student\\'s solution will be written\\n# to the file \\'submission.py\\'.\\nsubmission = SimpleNamespace(hello=hello)\\n\\n# BEGIN UNITTEST\\n# The unit tests main part is contained between \"BEGIN UNITTEST\" and \"END UNITTEST\". It will be copied\\n# verbatim into the autograder directory, with an addition of \\'import submission;\\'\\n\\nimport unittest\\n\\nclass HelloTest(unittest.TestCase):\\n    def test_one(self):\\n        self.assertEqual(submission.hello(\"one\"), \"Hello, one\")\\n        \\n    def test_bad(self):\\n        self.assertEqual(submission.hello(\"bad\"), \"Hello, good\")\\n        \\n# END UNITTEST\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       "  '# BEGIN AUTOTEST\\n# The tests below test that the unit test suite above produces expected outcomes from\\n# TODO(salikh): Figure out the right syntax for autotests.\\ndef wrong_hello(name):\\n    return \"Bye, \" + name\\n\\nimport unittest\\n\\nsubmission.hello = wrong_hello\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors,  resultclass=SummaryTestResult).run(suite)\\n\\nprint(result.results)\\nassert(result.results[\\'HelloTest.test_bad\\'] == False)\\nassert(result.results[\\'HelloTest.test_one\\'] == False)',\n",
       "  'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"my cell magic\"\"\"\\n    return cell\\n\\ndel submission',\n",
       "  \"get_ipython().run_cell_magic('submission', '', 'def syntax_error(name:\\\\n    return name\\\\n')\",\n",
       "  \"result = get_ipython().run_line_magic('autotest(HelloTest)', '')\\nassert(result['HelloTest.test_bad'] == False)\",\n",
       "  'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"A magic to mark a textual submission, possibly incorrect and unparseable.\"\"\"\\n    return cell\\n\\n@register_line_magic\\ndef autotest(line):\\n    \"\"\"A magic to run an auto test: run previously defined unit tests with a submission just given.\"\"\"\\n    return eval(line)\\n\\ndel submission, autotest',\n",
       "  \"get_ipython().run_cell_magic('submission', '', 'def syntax_error(name:\\\\n    return name\\\\n')\",\n",
       "  \"result = get_ipython().run_line_magic('autotest(HelloTest)', '')\\nassert(result['HelloTest.test_bad'] == False)\",\n",
       "  \"get_ipython().run_cell_magic('submission', '', 'def syntax_error(name:\\\\n    return name\\\\n')\",\n",
       "  \"result = get_ipython().run_line_magic('autotest', 'HelloTest')\\nassert(result['HelloTest.test_bad'] == False)\",\n",
       "  \"result = get_ipython().run_line_magic('autotest', 'HelloTest')\\nresult\\n#assert(result['HelloTest.test_bad'] == False)\",\n",
       "  \"result = get_ipython().run_line_magic('autotest', 'HelloTest')\\nresult\\n#assert(result['HelloTest.test_bad'] == False)\",\n",
       "  'print(\"hello\")',\n",
       "  'print(\"bye bye\")',\n",
       "  'print(\"hey\", \"you\")',\n",
       "  'print(\"one\")\\nprint(\"two\")',\n",
       "  '\"\"\" # BEGIN PROMPT\\n   # ... put your program here\\n   pass\\n\"\"\" # END PROMPT\\ndef printHello():\\n    # BEGIN SOLUTION\\n    print(\"Hello, world\")\\n    # END SOLUTION',\n",
       "  '# This will not be included in the student notebook because of BEGIN UNITTEST marker below.\\n\\n# Imitate the \\'import submission\\' environment with ad-hoc object.\\nfrom types import SimpleNamespace\\nsubmission = SimpleNamespace(printHello=printHello)\\n\\n# BEGIN UNITTEST\\nimport unittest\\n\\nimport sys\\nimport io\\nfrom contextlib import contextmanager\\nfrom io import StringIO\\n\\n@contextmanager\\ndef capture_output():\\n    capture_out, capture_err = StringIO(), StringIO()\\n    save_out, save_err = sys.stdout, sys.stderr\\n    try:\\n        sys.stdout, sys.stderr = capture_out, capture_err\\n        yield sys.stdout, sys.stderr\\n    finally:\\n        sys.stdout, sys.stderr = save_out, save_err\\n\\nclass HelloOutputTest(unittest.TestCase):\\n    def test_output(self):\\n        with capture_output() as (out, err):\\n            submission.printHello()\\n        self.assertEqual(err.getvalue(), \"\")\\n        self.assertEqual(out.getvalue(), \"Hello, world\\\\n\")\\n\\n# END UNITTEST\\n\\n# The parts after END UNITTEST are executed in the notebook environment, but not copied\\n# to the autograder scripts or to student notebooks.\\n\\n# TODO(salikh): Move this into a shared library and make that library installable via pip.\\nclass SummaryTestResult(unittest.TextTestResult):\\n    \"\"\"A small extension of TextTestResult that also collects a map of test statuses.\\n    \\n    \\n    result.results is a map from test name (string) to boolean: True(passed) or False(failed or error)\"\"\"\\n    \\n    separator1 = \\'=\\' * 70\\n    separator2 = \\'-\\' * 70\\n    \\n    def __init__(self, stream, descriptions, verbosity):\\n        super(unittest.TextTestResult, self).__init__(stream, descriptions, verbosity)\\n        # A map of test name to True(passed) or False(failed or error)\\n        self.results = {}\\n        # Copied from TextTestResult.\\n        self.stream = stream\\n        self.showAll = verbosity > 1\\n        self.dots = verbosity == 1\\n        self.descriptions = descriptions\\n\\n    def testName(self, test):\\n        \"\"\"A helper function to format the test as a human-readable string.\\n        \\n        The format is TestClassName.test_method. This is similar\\n        to TextTestResult.getDescription(test), but uses different format.\\n        getDescription: \\'test_one (__main__.HelloTest)\\'\\n        testName: \\'HelloTest.test_one\\'\\n        \"\"\"\\n        return unittest.util.strclass(test.__class__).replace(\\'__main__.\\', \\'\\') + \\'.\\' + test._testMethodName\\n        \\n    def getDescription(self, test):\\n        doc_first_line = test.shortDescription()\\n        if self.descriptions and doc_first_line:\\n            return \\'\\\\n\\'.join((str(test), doc_first_line))\\n        else:\\n            return str(test)\\n\\n    def startTest(self, test):\\n        super(unittest.TextTestResult, self).startTest(test)\\n        if self.showAll:\\n            self.stream.write(self.getDescription(test))\\n            self.stream.write(\" ... \")\\n            self.stream.flush()\\n\\n    def addSuccess(self, test):\\n        super(unittest.TextTestResult, self).addSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"ok\")\\n        elif self.dots:\\n            self.stream.write(\\'.\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = True\\n\\n    def addError(self, test, err):\\n        super(unittest.TextTestResult, self).addError(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"ERROR\")\\n        elif self.dots:\\n            self.stream.write(\\'E\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"FAIL\")\\n        elif self.dots:\\n            self.stream.write(\\'F\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addSkip(self, test, reason):\\n        super(unittest.TextTestResult, self).addSkip(test, reason)\\n        if self.showAll:\\n            self.stream.writeln(\"skipped {0!r}\".format(reason))\\n        elif self.dots:\\n            self.stream.write(\"s\")\\n            self.stream.flush()\\n\\n    def addExpectedFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addExpectedFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"expected failure\")\\n        elif self.dots:\\n            self.stream.write(\"x\")\\n            self.stream.flush()\\n\\n    def addUnexpectedSuccess(self, test):\\n        super(unittest.TextTestResult, self).addUnexpectedSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"unexpected success\")\\n        elif self.dots:\\n            self.stream.write(\"u\")\\n            self.stream.flush()\\n\\n    def printErrors(self):\\n        if self.dots or self.showAll:\\n            self.stream.writeln()\\n        self.printErrorList(\\'ERROR\\', self.errors)\\n        self.printErrorList(\\'FAIL\\', self.failures)\\n\\n    def printErrorList(self, flavour, errors):\\n        for test, err in errors:\\n            self.stream.writeln(self.separator1)\\n            self.stream.writeln(\"%s: %s\" % (flavour,self.getDescription(test)))\\n            self.stream.writeln(self.separator2)\\n            self.stream.writeln(\"%s\" % err)\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloOutputTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       "  'def hello(name):\\n    \"\"\" # BEGIN PROMPT\\n    # Please put your solution here:\\n    # return ...\\n    pass\\n    \"\"\" # END PROMPT\\n    # BEGIN SOLUTION\\n    return \"Hello, \" + name\\n    # END SOLUTION',\n",
       "  '# TEST\\nassert(hello(\"world\") == \"Hello, world\")',\n",
       "  '# The part before \"BEGIN UNITTEST\" -- preamble -- sets up the environment so that \\'submission.hello\\'\\n# is a function that we need to test. In the autograder worker environment, the preamble will be\\n# replaced with \\'import submission\\' with an assumption that the student\\'s solution will be written\\n# to the file \\'submission.py\\'.\\nsubmission = SimpleNamespace(hello=hello)\\n\\n# BEGIN UNITTEST\\n# The unit tests main part is contained between \"BEGIN UNITTEST\" and \"END UNITTEST\". It will be copied\\n# verbatim into the autograder directory, with an addition of \\'import submission;\\'\\n\\nimport unittest\\n\\nclass HelloTest(unittest.TestCase):\\n    def test_one(self):\\n        self.assertEqual(submission.hello(\"one\"), \"Hello, one\")\\n        \\n    def test_bad(self):\\n        self.assertEqual(submission.hello(\"bad\"), \"Hello, good\")\\n        \\n# END UNITTEST\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       "  '# BEGIN AUTOTEST\\n# The tests below test that the unit test suite above produces expected outcomes from\\n# TODO(salikh): Figure out the right syntax for autotests.\\ndef wrong_hello(name):\\n    return \"Bye, \" + name\\n\\nimport unittest\\n\\nsubmission.hello = wrong_hello\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors,  resultclass=SummaryTestResult).run(suite)\\n\\nprint(result.results)\\nassert(result.results[\\'HelloTest.test_bad\\'] == False)\\nassert(result.results[\\'HelloTest.test_one\\'] == False)',\n",
       "  'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"A magic to mark a textual submission, possibly incorrect and unparseable.\"\"\"\\n    return cell\\n\\n@register_line_magic\\ndef autotest(line):\\n    \"\"\"A magic to run an auto test: run previously defined unit tests with a submission just given.\"\"\"\\n    return eval(line)\\n\\ndel submission, autotest',\n",
       "  \"get_ipython().run_cell_magic('submission', '', 'def syntax_error(name:\\\\n    return name\\\\n')\",\n",
       "  \"result = get_ipython().run_line_magic('autotest', 'HelloTest')\\nresult\\n#assert(result['HelloTest.test_bad'] == False)\",\n",
       "  'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_line_magic\\ndef lmagic(line):\\n    \"my line magic\"\\n    return line\\n\\n@register_cell_magic\\ndef cmagic(line, cell):\\n    \"my cell magic\"\\n    return cell\\n\\ndel lmagic, cmagic',\n",
       "  'x = get_ipython().run_line_magic(\\'lmagic\\', \\'a b c\\')\\nprint(\"Hello, \" +x)',\n",
       "  \"get_ipython().run_cell_magic('cmagic', '', 'my cell magic\\\\nasfd\\\\n')\",\n",
       "  'vars()',\n",
       "  'from IPython.core.magic import (Magics, magics_class, line_magic,\\n                                cell_magic, line_cell_magic)\\n\\n# The class MUST call this class decorator at creation time\\n@magics_class\\nclass MyMagics(Magics):\\n\\n    @line_magic\\n    def lmagic(self, line):\\n        \"my line magic\"\\n        print(\"Full access to the main IPython object:\", self.shell)\\n        print(\"Variables in the user namespace:\", list(self.shell.user_ns.keys()))\\n        return line\\n\\n    @cell_magic\\n    def cmagic(self, line, cell):\\n        \"my cell magic\"\\n        return line, cell\\n\\n    @line_cell_magic\\n    def lcmagic(self, line, cell=None):\\n        \"Magic that works both as %lcmagic and as %%lcmagic\"\\n        if cell is None:\\n            print(\"Called as line magic\")\\n            return line\\n        else:\\n            print(\"Called as cell magic\")\\n            return line, cell\\n        \\nip = get_ipython()\\nip.register_magics(MyMagics)',\n",
       "  \"get_ipython().run_line_magic('lmagic', 'ab cd ef')\",\n",
       "  'print(\"hello\")',\n",
       "  'print(\"bye bye\")',\n",
       "  'print(\"hey\", \"you\")',\n",
       "  'print(\"one\")\\nprint(\"two\")',\n",
       "  '\"\"\" # BEGIN PROMPT\\n   # ... put your program here\\n   pass\\n\"\"\" # END PROMPT\\ndef printHello():\\n    # BEGIN SOLUTION\\n    print(\"Hello, world\")\\n    # END SOLUTION',\n",
       "  '# This will not be included in the student notebook because of BEGIN UNITTEST marker below.\\n\\n# Imitate the \\'import submission\\' environment with ad-hoc object.\\nfrom types import SimpleNamespace\\nsubmission = SimpleNamespace(printHello=printHello)\\n\\n# BEGIN UNITTEST\\nimport unittest\\n\\nimport sys\\nimport io\\nfrom contextlib import contextmanager\\nfrom io import StringIO\\n\\n@contextmanager\\ndef capture_output():\\n    capture_out, capture_err = StringIO(), StringIO()\\n    save_out, save_err = sys.stdout, sys.stderr\\n    try:\\n        sys.stdout, sys.stderr = capture_out, capture_err\\n        yield sys.stdout, sys.stderr\\n    finally:\\n        sys.stdout, sys.stderr = save_out, save_err\\n\\nclass HelloOutputTest(unittest.TestCase):\\n    def test_output(self):\\n        with capture_output() as (out, err):\\n            submission.printHello()\\n        self.assertEqual(err.getvalue(), \"\")\\n        self.assertEqual(out.getvalue(), \"Hello, world\\\\n\")\\n\\n# END UNITTEST\\n\\n# The parts after END UNITTEST are executed in the notebook environment, but not copied\\n# to the autograder scripts or to student notebooks.\\n\\n# TODO(salikh): Move this into a shared library and make that library installable via pip.\\nclass SummaryTestResult(unittest.TextTestResult):\\n    \"\"\"A small extension of TextTestResult that also collects a map of test statuses.\\n    \\n    \\n    result.results is a map from test name (string) to boolean: True(passed) or False(failed or error)\"\"\"\\n    \\n    separator1 = \\'=\\' * 70\\n    separator2 = \\'-\\' * 70\\n    \\n    def __init__(self, stream, descriptions, verbosity):\\n        super(unittest.TextTestResult, self).__init__(stream, descriptions, verbosity)\\n        # A map of test name to True(passed) or False(failed or error)\\n        self.results = {}\\n        # Copied from TextTestResult.\\n        self.stream = stream\\n        self.showAll = verbosity > 1\\n        self.dots = verbosity == 1\\n        self.descriptions = descriptions\\n\\n    def testName(self, test):\\n        \"\"\"A helper function to format the test as a human-readable string.\\n        \\n        The format is TestClassName.test_method. This is similar\\n        to TextTestResult.getDescription(test), but uses different format.\\n        getDescription: \\'test_one (__main__.HelloTest)\\'\\n        testName: \\'HelloTest.test_one\\'\\n        \"\"\"\\n        return unittest.util.strclass(test.__class__).replace(\\'__main__.\\', \\'\\') + \\'.\\' + test._testMethodName\\n        \\n    def getDescription(self, test):\\n        doc_first_line = test.shortDescription()\\n        if self.descriptions and doc_first_line:\\n            return \\'\\\\n\\'.join((str(test), doc_first_line))\\n        else:\\n            return str(test)\\n\\n    def startTest(self, test):\\n        super(unittest.TextTestResult, self).startTest(test)\\n        if self.showAll:\\n            self.stream.write(self.getDescription(test))\\n            self.stream.write(\" ... \")\\n            self.stream.flush()\\n\\n    def addSuccess(self, test):\\n        super(unittest.TextTestResult, self).addSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"ok\")\\n        elif self.dots:\\n            self.stream.write(\\'.\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = True\\n\\n    def addError(self, test, err):\\n        super(unittest.TextTestResult, self).addError(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"ERROR\")\\n        elif self.dots:\\n            self.stream.write(\\'E\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"FAIL\")\\n        elif self.dots:\\n            self.stream.write(\\'F\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addSkip(self, test, reason):\\n        super(unittest.TextTestResult, self).addSkip(test, reason)\\n        if self.showAll:\\n            self.stream.writeln(\"skipped {0!r}\".format(reason))\\n        elif self.dots:\\n            self.stream.write(\"s\")\\n            self.stream.flush()\\n\\n    def addExpectedFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addExpectedFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"expected failure\")\\n        elif self.dots:\\n            self.stream.write(\"x\")\\n            self.stream.flush()\\n\\n    def addUnexpectedSuccess(self, test):\\n        super(unittest.TextTestResult, self).addUnexpectedSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"unexpected success\")\\n        elif self.dots:\\n            self.stream.write(\"u\")\\n            self.stream.flush()\\n\\n    def printErrors(self):\\n        if self.dots or self.showAll:\\n            self.stream.writeln()\\n        self.printErrorList(\\'ERROR\\', self.errors)\\n        self.printErrorList(\\'FAIL\\', self.failures)\\n\\n    def printErrorList(self, flavour, errors):\\n        for test, err in errors:\\n            self.stream.writeln(self.separator1)\\n            self.stream.writeln(\"%s: %s\" % (flavour,self.getDescription(test)))\\n            self.stream.writeln(self.separator2)\\n            self.stream.writeln(\"%s\" % err)\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloOutputTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       "  'def hello(name):\\n    \"\"\" # BEGIN PROMPT\\n    # Please put your solution here:\\n    # return ...\\n    pass\\n    \"\"\" # END PROMPT\\n    # BEGIN SOLUTION\\n    return \"Hello, \" + name\\n    # END SOLUTION',\n",
       "  '# TEST\\nassert(hello(\"world\") == \"Hello, world\")',\n",
       "  '# The part before \"BEGIN UNITTEST\" -- preamble -- sets up the environment so that \\'submission.hello\\'\\n# is a function that we need to test. In the autograder worker environment, the preamble will be\\n# replaced with \\'import submission\\' with an assumption that the student\\'s solution will be written\\n# to the file \\'submission.py\\'.\\nsubmission = SimpleNamespace(hello=hello)\\n\\n# BEGIN UNITTEST\\n# The unit tests main part is contained between \"BEGIN UNITTEST\" and \"END UNITTEST\". It will be copied\\n# verbatim into the autograder directory, with an addition of \\'import submission;\\'\\n\\nimport unittest\\n\\nclass HelloTest(unittest.TestCase):\\n    def test_one(self):\\n        self.assertEqual(submission.hello(\"one\"), \"Hello, one\")\\n        \\n    def test_bad(self):\\n        self.assertEqual(submission.hello(\"bad\"), \"Hello, good\")\\n        \\n# END UNITTEST\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       "  '# BEGIN AUTOTEST\\n# The tests below test that the unit test suite above produces expected outcomes from\\n# TODO(salikh): Figure out the right syntax for autotests.\\ndef wrong_hello(name):\\n    return \"Bye, \" + name\\n\\nimport unittest\\n\\nsubmission.hello = wrong_hello\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors,  resultclass=SummaryTestResult).run(suite)\\n\\nprint(result.results)\\nassert(result.results[\\'HelloTest.test_bad\\'] == False)\\nassert(result.results[\\'HelloTest.test_one\\'] == False)',\n",
       "  'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"A magic to mark a textual submission, possibly incorrect and unparseable.\"\"\"\\n    return cell\\n\\n@register_line_magic\\ndef autotest(line):\\n    \"\"\"A magic to run an auto test: run previously defined unit tests with a submission just given.\"\"\"\\n    return eval(line)\\n\\ndel submission, autotest',\n",
       "  \"get_ipython().run_cell_magic('submission', '', 'def syntax_error(name:\\\\n    return name\\\\n')\",\n",
       "  \"result = get_ipython().run_line_magic('autotest', 'HelloTest')\\nresult\\n#assert(result['HelloTest.test_bad'] == False)\",\n",
       "  'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_line_magic\\ndef lmagic(line):\\n    \"my line magic\"\\n    return line\\n\\n@register_cell_magic\\ndef cmagic(line, cell):\\n    \"my cell magic\"\\n    return cell\\n\\ndel lmagic, cmagic',\n",
       "  'x = get_ipython().run_line_magic(\\'lmagic\\', \\'a b c\\')\\nprint(\"Hello, \" +x)',\n",
       "  \"get_ipython().run_cell_magic('cmagic', '', 'my cell magic\\\\nasfd\\\\n')\",\n",
       "  'vars()'],\n",
       " 'Out': {15: 'def syntax_error(name:\\n    return name\\n',\n",
       "  28: 'def syntax_error(name:\\n    return name\\n',\n",
       "  31: 'def syntax_error(name:\\n    return name\\n',\n",
       "  33: 'def syntax_error(name:\\n    return name\\n',\n",
       "  35: __main__.HelloTest,\n",
       "  36: __main__.HelloTest,\n",
       "  48: 'def syntax_error(name:\\n    return name\\n',\n",
       "  49: __main__.HelloTest,\n",
       "  52: 'my cell magic\\nasfd\\n',\n",
       "  53: {...},\n",
       "  55: 'ab cd ef',\n",
       "  67: 'def syntax_error(name:\\n    return name\\n',\n",
       "  68: __main__.HelloTest,\n",
       "  71: 'my cell magic\\nasfd\\n'},\n",
       " 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7fc6f8cd84e0>>,\n",
       " 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x7fc6f8cb55c0>,\n",
       " 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x7fc6f8cb55c0>,\n",
       " '_': 'my cell magic\\nasfd\\n',\n",
       " '__': __main__.HelloTest,\n",
       " '___': 'def syntax_error(name:\\n    return name\\n',\n",
       " '_i': '%%cmagic\\nmy cell magic\\nasfd',\n",
       " '_ii': 'x = %lmagic a b c\\nprint(\"Hello, \" +x)',\n",
       " '_iii': 'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_line_magic\\ndef lmagic(line):\\n    \"my line magic\"\\n    return line\\n\\n@register_cell_magic\\ndef cmagic(line, cell):\\n    \"my cell magic\"\\n    return cell\\n\\ndel lmagic, cmagic',\n",
       " '_i1': 'print(\"hello\")',\n",
       " '_i2': 'print(\"bye bye\")',\n",
       " '_i3': 'print(\"hey\", \"you\")',\n",
       " '_i4': 'print(\"one\")\\nprint(\"two\")',\n",
       " '_i5': '\"\"\" # BEGIN PROMPT\\n   # ... put your program here\\n   pass\\n\"\"\" # END PROMPT\\ndef printHello():\\n    # BEGIN SOLUTION\\n    print(\"Hello, world\")\\n    # END SOLUTION',\n",
       " 'printHello': <function __main__.printHello()>,\n",
       " '_i6': '# This will not be included in the student notebook because of BEGIN UNITTEST marker below.\\n\\n# Imitate the \\'import submission\\' environment with ad-hoc object.\\nfrom types import SimpleNamespace\\nsubmission = SimpleNamespace(printHello=printHello)\\n\\n# BEGIN UNITTEST\\nimport unittest\\n\\nimport sys\\nimport io\\nfrom contextlib import contextmanager\\nfrom io import StringIO\\n\\n@contextmanager\\ndef capture_output():\\n    capture_out, capture_err = StringIO(), StringIO()\\n    save_out, save_err = sys.stdout, sys.stderr\\n    try:\\n        sys.stdout, sys.stderr = capture_out, capture_err\\n        yield sys.stdout, sys.stderr\\n    finally:\\n        sys.stdout, sys.stderr = save_out, save_err\\n\\nclass HelloOutputTest(unittest.TestCase):\\n    def test_output(self):\\n        with capture_output() as (out, err):\\n            submission.printHello()\\n        self.assertEqual(err.getvalue(), \"\")\\n        self.assertEqual(out.getvalue(), \"Hello, world\\\\n\")\\n\\n# END UNITTEST\\n\\n# The parts after END UNITTEST are executed in the notebook environment, but not copied\\n# to the autograder scripts or to student notebooks.\\n\\n# TODO(salikh): Move this into a shared library and make that library installable via pip.\\nclass SummaryTestResult(unittest.TextTestResult):\\n    \"\"\"A small extension of TextTestResult that also collects a map of test statuses.\\n    \\n    \\n    result.results is a map from test name (string) to boolean: True(passed) or False(failed or error)\"\"\"\\n    \\n    separator1 = \\'=\\' * 70\\n    separator2 = \\'-\\' * 70\\n    \\n    def __init__(self, stream, descriptions, verbosity):\\n        super(unittest.TextTestResult, self).__init__(stream, descriptions, verbosity)\\n        # A map of test name to True(passed) or False(failed or error)\\n        self.results = {}\\n        # Copied from TextTestResult.\\n        self.stream = stream\\n        self.showAll = verbosity > 1\\n        self.dots = verbosity == 1\\n        self.descriptions = descriptions\\n\\n    def testName(self, test):\\n        \"\"\"A helper function to format the test as a human-readable string.\\n        \\n        The format is TestClassName.test_method. This is similar\\n        to TextTestResult.getDescription(test), but uses different format.\\n        getDescription: \\'test_one (__main__.HelloTest)\\'\\n        testName: \\'HelloTest.test_one\\'\\n        \"\"\"\\n        return unittest.util.strclass(test.__class__).replace(\\'__main__.\\', \\'\\') + \\'.\\' + test._testMethodName\\n        \\n    def getDescription(self, test):\\n        doc_first_line = test.shortDescription()\\n        if self.descriptions and doc_first_line:\\n            return \\'\\\\n\\'.join((str(test), doc_first_line))\\n        else:\\n            return str(test)\\n\\n    def startTest(self, test):\\n        super(unittest.TextTestResult, self).startTest(test)\\n        if self.showAll:\\n            self.stream.write(self.getDescription(test))\\n            self.stream.write(\" ... \")\\n            self.stream.flush()\\n\\n    def addSuccess(self, test):\\n        super(unittest.TextTestResult, self).addSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"ok\")\\n        elif self.dots:\\n            self.stream.write(\\'.\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = True\\n\\n    def addError(self, test, err):\\n        super(unittest.TextTestResult, self).addError(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"ERROR\")\\n        elif self.dots:\\n            self.stream.write(\\'E\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"FAIL\")\\n        elif self.dots:\\n            self.stream.write(\\'F\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addSkip(self, test, reason):\\n        super(unittest.TextTestResult, self).addSkip(test, reason)\\n        if self.showAll:\\n            self.stream.writeln(\"skipped {0!r}\".format(reason))\\n        elif self.dots:\\n            self.stream.write(\"s\")\\n            self.stream.flush()\\n\\n    def addExpectedFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addExpectedFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"expected failure\")\\n        elif self.dots:\\n            self.stream.write(\"x\")\\n            self.stream.flush()\\n\\n    def addUnexpectedSuccess(self, test):\\n        super(unittest.TextTestResult, self).addUnexpectedSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"unexpected success\")\\n        elif self.dots:\\n            self.stream.write(\"u\")\\n            self.stream.flush()\\n\\n    def printErrors(self):\\n        if self.dots or self.showAll:\\n            self.stream.writeln()\\n        self.printErrorList(\\'ERROR\\', self.errors)\\n        self.printErrorList(\\'FAIL\\', self.failures)\\n\\n    def printErrorList(self, flavour, errors):\\n        for test, err in errors:\\n            self.stream.writeln(self.separator1)\\n            self.stream.writeln(\"%s: %s\" % (flavour,self.getDescription(test)))\\n            self.stream.writeln(self.separator2)\\n            self.stream.writeln(\"%s\" % err)\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloOutputTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       " 'SimpleNamespace': types.SimpleNamespace,\n",
       " 'unittest': <module 'unittest' from '/usr/lib/python3.6/unittest/__init__.py'>,\n",
       " 'sys': <module 'sys' (built-in)>,\n",
       " 'io': <module 'io' from '/home/salikh/uot/venv/lib/python3.6/io.py'>,\n",
       " 'contextmanager': <function contextlib.contextmanager(func)>,\n",
       " 'StringIO': _io.StringIO,\n",
       " 'capture_output': <function __main__.capture_output()>,\n",
       " 'HelloOutputTest': __main__.HelloOutputTest,\n",
       " 'SummaryTestResult': __main__.SummaryTestResult,\n",
       " 'suite': <unittest.suite.TestSuite tests=[None, None]>,\n",
       " 'errors': <_io.StringIO at 0x7fc6f4a46b88>,\n",
       " 'result': __main__.HelloTest,\n",
       " '_i7': 'def hello(name):\\n    \"\"\" # BEGIN PROMPT\\n    # Please put your solution here:\\n    # return ...\\n    pass\\n    \"\"\" # END PROMPT\\n    # BEGIN SOLUTION\\n    return \"Hello, \" + name\\n    # END SOLUTION',\n",
       " 'hello': <function __main__.hello(name)>,\n",
       " '_i8': '# TEST\\nassert(hello(\"world\") == \"Hello, world\")',\n",
       " '_i9': '# The part before \"BEGIN UNITTEST\" -- preamble -- sets up the environment so that \\'submission.hello\\'\\n# is a function that we need to test. In the autograder worker environment, the preamble will be\\n# replaced with \\'import submission\\' with an assumption that the student\\'s solution will be written\\n# to the file \\'submission.py\\'.\\nsubmission = SimpleNamespace(hello=hello)\\n\\n# BEGIN UNITTEST\\n# The unit tests main part is contained between \"BEGIN UNITTEST\" and \"END UNITTEST\". It will be copied\\n# verbatim into the autograder directory, with an addition of \\'import submission;\\'\\n\\nimport unittest\\n\\nclass HelloTest(unittest.TestCase):\\n    def test_one(self):\\n        self.assertEqual(submission.hello(\"one\"), \"Hello, one\")\\n        \\n    def test_bad(self):\\n        self.assertEqual(submission.hello(\"bad\"), \"Hello, good\")\\n        \\n# END UNITTEST\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       " 'HelloTest': __main__.HelloTest,\n",
       " '_i10': '# BEGIN AUTOTEST\\n# The tests below test that the unit test suite above produces expected outcomes from\\n# TODO(salikh): Figure out the right syntax for autotests.\\ndef wrong_hello(name):\\n    return \"Bye, \" + name\\n\\nimport unittest\\n\\nsubmission.hello = wrong_hello\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors,  resultclass=SummaryTestResult).run(suite)\\n\\nprint(result.results)\\nassert(result.results[\\'HelloTest.test_bad\\'] == False)\\nassert(result.results[\\'HelloTest.test_one\\'] == False)',\n",
       " 'wrong_hello': <function __main__.wrong_hello(name)>,\n",
       " '_i11': '%%submission\\ndef syntax_error(name:\\n    return name',\n",
       " '_i12': 'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"my cell magic\"\"\"\\n    return cell\\n\\ndel lmagic, cmagic',\n",
       " 'register_line_magic': <function IPython.core.magic._function_magic_marker.<locals>.magic_deco(arg)>,\n",
       " 'register_cell_magic': <function IPython.core.magic._function_magic_marker.<locals>.magic_deco(arg)>,\n",
       " 'register_line_cell_magic': <function IPython.core.magic._function_magic_marker.<locals>.magic_deco(arg)>,\n",
       " '_i13': 'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"my cell magic\"\"\"\\n    return cell\\n\\ndel submission',\n",
       " '_i14': '#%%submission\\ndef syntax_error(name:\\n    return name',\n",
       " '_i15': '%%submission\\ndef syntax_error(name:\\n    return name',\n",
       " '_15': 'def syntax_error(name:\\n    return name\\n',\n",
       " '_i16': 'x = %%submission\\ndef syntax_error(name:\\n    return name',\n",
       " '_i17': 'print(\"hello\")',\n",
       " '_i18': 'print(\"bye bye\")',\n",
       " '_i19': 'print(\"hey\", \"you\")',\n",
       " '_i20': 'print(\"one\")\\nprint(\"two\")',\n",
       " '_i21': '\"\"\" # BEGIN PROMPT\\n   # ... put your program here\\n   pass\\n\"\"\" # END PROMPT\\ndef printHello():\\n    # BEGIN SOLUTION\\n    print(\"Hello, world\")\\n    # END SOLUTION',\n",
       " '_i22': '# This will not be included in the student notebook because of BEGIN UNITTEST marker below.\\n\\n# Imitate the \\'import submission\\' environment with ad-hoc object.\\nfrom types import SimpleNamespace\\nsubmission = SimpleNamespace(printHello=printHello)\\n\\n# BEGIN UNITTEST\\nimport unittest\\n\\nimport sys\\nimport io\\nfrom contextlib import contextmanager\\nfrom io import StringIO\\n\\n@contextmanager\\ndef capture_output():\\n    capture_out, capture_err = StringIO(), StringIO()\\n    save_out, save_err = sys.stdout, sys.stderr\\n    try:\\n        sys.stdout, sys.stderr = capture_out, capture_err\\n        yield sys.stdout, sys.stderr\\n    finally:\\n        sys.stdout, sys.stderr = save_out, save_err\\n\\nclass HelloOutputTest(unittest.TestCase):\\n    def test_output(self):\\n        with capture_output() as (out, err):\\n            submission.printHello()\\n        self.assertEqual(err.getvalue(), \"\")\\n        self.assertEqual(out.getvalue(), \"Hello, world\\\\n\")\\n\\n# END UNITTEST\\n\\n# The parts after END UNITTEST are executed in the notebook environment, but not copied\\n# to the autograder scripts or to student notebooks.\\n\\n# TODO(salikh): Move this into a shared library and make that library installable via pip.\\nclass SummaryTestResult(unittest.TextTestResult):\\n    \"\"\"A small extension of TextTestResult that also collects a map of test statuses.\\n    \\n    \\n    result.results is a map from test name (string) to boolean: True(passed) or False(failed or error)\"\"\"\\n    \\n    separator1 = \\'=\\' * 70\\n    separator2 = \\'-\\' * 70\\n    \\n    def __init__(self, stream, descriptions, verbosity):\\n        super(unittest.TextTestResult, self).__init__(stream, descriptions, verbosity)\\n        # A map of test name to True(passed) or False(failed or error)\\n        self.results = {}\\n        # Copied from TextTestResult.\\n        self.stream = stream\\n        self.showAll = verbosity > 1\\n        self.dots = verbosity == 1\\n        self.descriptions = descriptions\\n\\n    def testName(self, test):\\n        \"\"\"A helper function to format the test as a human-readable string.\\n        \\n        The format is TestClassName.test_method. This is similar\\n        to TextTestResult.getDescription(test), but uses different format.\\n        getDescription: \\'test_one (__main__.HelloTest)\\'\\n        testName: \\'HelloTest.test_one\\'\\n        \"\"\"\\n        return unittest.util.strclass(test.__class__).replace(\\'__main__.\\', \\'\\') + \\'.\\' + test._testMethodName\\n        \\n    def getDescription(self, test):\\n        doc_first_line = test.shortDescription()\\n        if self.descriptions and doc_first_line:\\n            return \\'\\\\n\\'.join((str(test), doc_first_line))\\n        else:\\n            return str(test)\\n\\n    def startTest(self, test):\\n        super(unittest.TextTestResult, self).startTest(test)\\n        if self.showAll:\\n            self.stream.write(self.getDescription(test))\\n            self.stream.write(\" ... \")\\n            self.stream.flush()\\n\\n    def addSuccess(self, test):\\n        super(unittest.TextTestResult, self).addSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"ok\")\\n        elif self.dots:\\n            self.stream.write(\\'.\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = True\\n\\n    def addError(self, test, err):\\n        super(unittest.TextTestResult, self).addError(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"ERROR\")\\n        elif self.dots:\\n            self.stream.write(\\'E\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"FAIL\")\\n        elif self.dots:\\n            self.stream.write(\\'F\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addSkip(self, test, reason):\\n        super(unittest.TextTestResult, self).addSkip(test, reason)\\n        if self.showAll:\\n            self.stream.writeln(\"skipped {0!r}\".format(reason))\\n        elif self.dots:\\n            self.stream.write(\"s\")\\n            self.stream.flush()\\n\\n    def addExpectedFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addExpectedFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"expected failure\")\\n        elif self.dots:\\n            self.stream.write(\"x\")\\n            self.stream.flush()\\n\\n    def addUnexpectedSuccess(self, test):\\n        super(unittest.TextTestResult, self).addUnexpectedSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"unexpected success\")\\n        elif self.dots:\\n            self.stream.write(\"u\")\\n            self.stream.flush()\\n\\n    def printErrors(self):\\n        if self.dots or self.showAll:\\n            self.stream.writeln()\\n        self.printErrorList(\\'ERROR\\', self.errors)\\n        self.printErrorList(\\'FAIL\\', self.failures)\\n\\n    def printErrorList(self, flavour, errors):\\n        for test, err in errors:\\n            self.stream.writeln(self.separator1)\\n            self.stream.writeln(\"%s: %s\" % (flavour,self.getDescription(test)))\\n            self.stream.writeln(self.separator2)\\n            self.stream.writeln(\"%s\" % err)\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloOutputTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       " '_i23': 'def hello(name):\\n    \"\"\" # BEGIN PROMPT\\n    # Please put your solution here:\\n    # return ...\\n    pass\\n    \"\"\" # END PROMPT\\n    # BEGIN SOLUTION\\n    return \"Hello, \" + name\\n    # END SOLUTION',\n",
       " '_i24': '# TEST\\nassert(hello(\"world\") == \"Hello, world\")',\n",
       " '_i25': '# The part before \"BEGIN UNITTEST\" -- preamble -- sets up the environment so that \\'submission.hello\\'\\n# is a function that we need to test. In the autograder worker environment, the preamble will be\\n# replaced with \\'import submission\\' with an assumption that the student\\'s solution will be written\\n# to the file \\'submission.py\\'.\\nsubmission = SimpleNamespace(hello=hello)\\n\\n# BEGIN UNITTEST\\n# The unit tests main part is contained between \"BEGIN UNITTEST\" and \"END UNITTEST\". It will be copied\\n# verbatim into the autograder directory, with an addition of \\'import submission;\\'\\n\\nimport unittest\\n\\nclass HelloTest(unittest.TestCase):\\n    def test_one(self):\\n        self.assertEqual(submission.hello(\"one\"), \"Hello, one\")\\n        \\n    def test_bad(self):\\n        self.assertEqual(submission.hello(\"bad\"), \"Hello, good\")\\n        \\n# END UNITTEST\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       " '_i26': '# BEGIN AUTOTEST\\n# The tests below test that the unit test suite above produces expected outcomes from\\n# TODO(salikh): Figure out the right syntax for autotests.\\ndef wrong_hello(name):\\n    return \"Bye, \" + name\\n\\nimport unittest\\n\\nsubmission.hello = wrong_hello\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors,  resultclass=SummaryTestResult).run(suite)\\n\\nprint(result.results)\\nassert(result.results[\\'HelloTest.test_bad\\'] == False)\\nassert(result.results[\\'HelloTest.test_one\\'] == False)',\n",
       " '_i27': 'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"my cell magic\"\"\"\\n    return cell\\n\\ndel submission',\n",
       " '_i28': '%%submission\\ndef syntax_error(name:\\n    return name',\n",
       " '_28': 'def syntax_error(name:\\n    return name\\n',\n",
       " '_i29': \"result = %autotest(HelloTest)\\nassert(result['HelloTest.test_bad'] == False)\",\n",
       " '_i30': 'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"A magic to mark a textual submission, possibly incorrect and unparseable.\"\"\"\\n    return cell\\n\\n@register_line_magic\\ndef autotest(line):\\n    \"\"\"A magic to run an auto test: run previously defined unit tests with a submission just given.\"\"\"\\n    return eval(line)\\n\\ndel submission, autotest',\n",
       " '_i31': '%%submission\\ndef syntax_error(name:\\n    return name',\n",
       " '_31': 'def syntax_error(name:\\n    return name\\n',\n",
       " '_i32': \"result = %autotest(HelloTest)\\nassert(result['HelloTest.test_bad'] == False)\",\n",
       " '_i33': '%%submission\\ndef syntax_error(name:\\n    return name',\n",
       " '_33': 'def syntax_error(name:\\n    return name\\n',\n",
       " '_i34': \"result = %autotest HelloTest\\nassert(result['HelloTest.test_bad'] == False)\",\n",
       " '_i35': \"result = %autotest HelloTest\\nresult\\n#assert(result['HelloTest.test_bad'] == False)\",\n",
       " '_35': __main__.HelloTest,\n",
       " '_i36': \"result = %autotest HelloTest\\nresult\\n#assert(result['HelloTest.test_bad'] == False)\",\n",
       " '_36': __main__.HelloTest,\n",
       " '_i37': 'print(\"hello\")',\n",
       " '_i38': 'print(\"bye bye\")',\n",
       " '_i39': 'print(\"hey\", \"you\")',\n",
       " '_i40': 'print(\"one\")\\nprint(\"two\")',\n",
       " '_i41': '\"\"\" # BEGIN PROMPT\\n   # ... put your program here\\n   pass\\n\"\"\" # END PROMPT\\ndef printHello():\\n    # BEGIN SOLUTION\\n    print(\"Hello, world\")\\n    # END SOLUTION',\n",
       " '_i42': '# This will not be included in the student notebook because of BEGIN UNITTEST marker below.\\n\\n# Imitate the \\'import submission\\' environment with ad-hoc object.\\nfrom types import SimpleNamespace\\nsubmission = SimpleNamespace(printHello=printHello)\\n\\n# BEGIN UNITTEST\\nimport unittest\\n\\nimport sys\\nimport io\\nfrom contextlib import contextmanager\\nfrom io import StringIO\\n\\n@contextmanager\\ndef capture_output():\\n    capture_out, capture_err = StringIO(), StringIO()\\n    save_out, save_err = sys.stdout, sys.stderr\\n    try:\\n        sys.stdout, sys.stderr = capture_out, capture_err\\n        yield sys.stdout, sys.stderr\\n    finally:\\n        sys.stdout, sys.stderr = save_out, save_err\\n\\nclass HelloOutputTest(unittest.TestCase):\\n    def test_output(self):\\n        with capture_output() as (out, err):\\n            submission.printHello()\\n        self.assertEqual(err.getvalue(), \"\")\\n        self.assertEqual(out.getvalue(), \"Hello, world\\\\n\")\\n\\n# END UNITTEST\\n\\n# The parts after END UNITTEST are executed in the notebook environment, but not copied\\n# to the autograder scripts or to student notebooks.\\n\\n# TODO(salikh): Move this into a shared library and make that library installable via pip.\\nclass SummaryTestResult(unittest.TextTestResult):\\n    \"\"\"A small extension of TextTestResult that also collects a map of test statuses.\\n    \\n    \\n    result.results is a map from test name (string) to boolean: True(passed) or False(failed or error)\"\"\"\\n    \\n    separator1 = \\'=\\' * 70\\n    separator2 = \\'-\\' * 70\\n    \\n    def __init__(self, stream, descriptions, verbosity):\\n        super(unittest.TextTestResult, self).__init__(stream, descriptions, verbosity)\\n        # A map of test name to True(passed) or False(failed or error)\\n        self.results = {}\\n        # Copied from TextTestResult.\\n        self.stream = stream\\n        self.showAll = verbosity > 1\\n        self.dots = verbosity == 1\\n        self.descriptions = descriptions\\n\\n    def testName(self, test):\\n        \"\"\"A helper function to format the test as a human-readable string.\\n        \\n        The format is TestClassName.test_method. This is similar\\n        to TextTestResult.getDescription(test), but uses different format.\\n        getDescription: \\'test_one (__main__.HelloTest)\\'\\n        testName: \\'HelloTest.test_one\\'\\n        \"\"\"\\n        return unittest.util.strclass(test.__class__).replace(\\'__main__.\\', \\'\\') + \\'.\\' + test._testMethodName\\n        \\n    def getDescription(self, test):\\n        doc_first_line = test.shortDescription()\\n        if self.descriptions and doc_first_line:\\n            return \\'\\\\n\\'.join((str(test), doc_first_line))\\n        else:\\n            return str(test)\\n\\n    def startTest(self, test):\\n        super(unittest.TextTestResult, self).startTest(test)\\n        if self.showAll:\\n            self.stream.write(self.getDescription(test))\\n            self.stream.write(\" ... \")\\n            self.stream.flush()\\n\\n    def addSuccess(self, test):\\n        super(unittest.TextTestResult, self).addSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"ok\")\\n        elif self.dots:\\n            self.stream.write(\\'.\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = True\\n\\n    def addError(self, test, err):\\n        super(unittest.TextTestResult, self).addError(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"ERROR\")\\n        elif self.dots:\\n            self.stream.write(\\'E\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"FAIL\")\\n        elif self.dots:\\n            self.stream.write(\\'F\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addSkip(self, test, reason):\\n        super(unittest.TextTestResult, self).addSkip(test, reason)\\n        if self.showAll:\\n            self.stream.writeln(\"skipped {0!r}\".format(reason))\\n        elif self.dots:\\n            self.stream.write(\"s\")\\n            self.stream.flush()\\n\\n    def addExpectedFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addExpectedFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"expected failure\")\\n        elif self.dots:\\n            self.stream.write(\"x\")\\n            self.stream.flush()\\n\\n    def addUnexpectedSuccess(self, test):\\n        super(unittest.TextTestResult, self).addUnexpectedSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"unexpected success\")\\n        elif self.dots:\\n            self.stream.write(\"u\")\\n            self.stream.flush()\\n\\n    def printErrors(self):\\n        if self.dots or self.showAll:\\n            self.stream.writeln()\\n        self.printErrorList(\\'ERROR\\', self.errors)\\n        self.printErrorList(\\'FAIL\\', self.failures)\\n\\n    def printErrorList(self, flavour, errors):\\n        for test, err in errors:\\n            self.stream.writeln(self.separator1)\\n            self.stream.writeln(\"%s: %s\" % (flavour,self.getDescription(test)))\\n            self.stream.writeln(self.separator2)\\n            self.stream.writeln(\"%s\" % err)\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloOutputTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       " '_i43': 'def hello(name):\\n    \"\"\" # BEGIN PROMPT\\n    # Please put your solution here:\\n    # return ...\\n    pass\\n    \"\"\" # END PROMPT\\n    # BEGIN SOLUTION\\n    return \"Hello, \" + name\\n    # END SOLUTION',\n",
       " '_i44': '# TEST\\nassert(hello(\"world\") == \"Hello, world\")',\n",
       " '_i45': '# The part before \"BEGIN UNITTEST\" -- preamble -- sets up the environment so that \\'submission.hello\\'\\n# is a function that we need to test. In the autograder worker environment, the preamble will be\\n# replaced with \\'import submission\\' with an assumption that the student\\'s solution will be written\\n# to the file \\'submission.py\\'.\\nsubmission = SimpleNamespace(hello=hello)\\n\\n# BEGIN UNITTEST\\n# The unit tests main part is contained between \"BEGIN UNITTEST\" and \"END UNITTEST\". It will be copied\\n# verbatim into the autograder directory, with an addition of \\'import submission;\\'\\n\\nimport unittest\\n\\nclass HelloTest(unittest.TestCase):\\n    def test_one(self):\\n        self.assertEqual(submission.hello(\"one\"), \"Hello, one\")\\n        \\n    def test_bad(self):\\n        self.assertEqual(submission.hello(\"bad\"), \"Hello, good\")\\n        \\n# END UNITTEST\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       " '_i46': '# BEGIN AUTOTEST\\n# The tests below test that the unit test suite above produces expected outcomes from\\n# TODO(salikh): Figure out the right syntax for autotests.\\ndef wrong_hello(name):\\n    return \"Bye, \" + name\\n\\nimport unittest\\n\\nsubmission.hello = wrong_hello\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors,  resultclass=SummaryTestResult).run(suite)\\n\\nprint(result.results)\\nassert(result.results[\\'HelloTest.test_bad\\'] == False)\\nassert(result.results[\\'HelloTest.test_one\\'] == False)',\n",
       " '_i47': 'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"A magic to mark a textual submission, possibly incorrect and unparseable.\"\"\"\\n    return cell\\n\\n@register_line_magic\\ndef autotest(line):\\n    \"\"\"A magic to run an auto test: run previously defined unit tests with a submission just given.\"\"\"\\n    return eval(line)\\n\\ndel submission, autotest',\n",
       " '_i48': '%%submission\\ndef syntax_error(name:\\n    return name',\n",
       " '_48': 'def syntax_error(name:\\n    return name\\n',\n",
       " '_i49': \"result = %autotest HelloTest\\nresult\\n#assert(result['HelloTest.test_bad'] == False)\",\n",
       " '_49': __main__.HelloTest,\n",
       " '_i50': 'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_line_magic\\ndef lmagic(line):\\n    \"my line magic\"\\n    return line\\n\\n@register_cell_magic\\ndef cmagic(line, cell):\\n    \"my cell magic\"\\n    return cell\\n\\ndel lmagic, cmagic',\n",
       " '_i51': 'x = %lmagic a b c\\nprint(\"Hello, \" +x)',\n",
       " 'x': 'a b c',\n",
       " '_i52': '%%cmagic\\nmy cell magic\\nasfd',\n",
       " '_52': 'my cell magic\\nasfd\\n',\n",
       " '_i53': 'vars()',\n",
       " '_53': {...},\n",
       " '_i54': 'from IPython.core.magic import (Magics, magics_class, line_magic,\\n                                cell_magic, line_cell_magic)\\n\\n# The class MUST call this class decorator at creation time\\n@magics_class\\nclass MyMagics(Magics):\\n\\n    @line_magic\\n    def lmagic(self, line):\\n        \"my line magic\"\\n        print(\"Full access to the main IPython object:\", self.shell)\\n        print(\"Variables in the user namespace:\", list(self.shell.user_ns.keys()))\\n        return line\\n\\n    @cell_magic\\n    def cmagic(self, line, cell):\\n        \"my cell magic\"\\n        return line, cell\\n\\n    @line_cell_magic\\n    def lcmagic(self, line, cell=None):\\n        \"Magic that works both as %lcmagic and as %%lcmagic\"\\n        if cell is None:\\n            print(\"Called as line magic\")\\n            return line\\n        else:\\n            print(\"Called as cell magic\")\\n            return line, cell\\n        \\nip = get_ipython()\\nip.register_magics(MyMagics)',\n",
       " 'Magics': IPython.core.magic.Magics,\n",
       " 'magics_class': <function IPython.core.magic.magics_class(cls)>,\n",
       " 'line_magic': <function IPython.core.magic._method_magic_marker.<locals>.magic_deco(arg)>,\n",
       " 'cell_magic': <function IPython.core.magic._method_magic_marker.<locals>.magic_deco(arg)>,\n",
       " 'line_cell_magic': <function IPython.core.magic._method_magic_marker.<locals>.magic_deco(arg)>,\n",
       " 'MyMagics': __main__.MyMagics,\n",
       " 'ip': <ipykernel.zmqshell.ZMQInteractiveShell at 0x7fc6f8cd84e0>,\n",
       " '_i55': '%lmagic ab cd ef',\n",
       " '_55': 'ab cd ef',\n",
       " '_i56': 'print(\"hello\")',\n",
       " '_i57': 'print(\"bye bye\")',\n",
       " '_i58': 'print(\"hey\", \"you\")',\n",
       " '_i59': 'print(\"one\")\\nprint(\"two\")',\n",
       " '_i60': '\"\"\" # BEGIN PROMPT\\n   # ... put your program here\\n   pass\\n\"\"\" # END PROMPT\\ndef printHello():\\n    # BEGIN SOLUTION\\n    print(\"Hello, world\")\\n    # END SOLUTION',\n",
       " '_i61': '# This will not be included in the student notebook because of BEGIN UNITTEST marker below.\\n\\n# Imitate the \\'import submission\\' environment with ad-hoc object.\\nfrom types import SimpleNamespace\\nsubmission = SimpleNamespace(printHello=printHello)\\n\\n# BEGIN UNITTEST\\nimport unittest\\n\\nimport sys\\nimport io\\nfrom contextlib import contextmanager\\nfrom io import StringIO\\n\\n@contextmanager\\ndef capture_output():\\n    capture_out, capture_err = StringIO(), StringIO()\\n    save_out, save_err = sys.stdout, sys.stderr\\n    try:\\n        sys.stdout, sys.stderr = capture_out, capture_err\\n        yield sys.stdout, sys.stderr\\n    finally:\\n        sys.stdout, sys.stderr = save_out, save_err\\n\\nclass HelloOutputTest(unittest.TestCase):\\n    def test_output(self):\\n        with capture_output() as (out, err):\\n            submission.printHello()\\n        self.assertEqual(err.getvalue(), \"\")\\n        self.assertEqual(out.getvalue(), \"Hello, world\\\\n\")\\n\\n# END UNITTEST\\n\\n# The parts after END UNITTEST are executed in the notebook environment, but not copied\\n# to the autograder scripts or to student notebooks.\\n\\n# TODO(salikh): Move this into a shared library and make that library installable via pip.\\nclass SummaryTestResult(unittest.TextTestResult):\\n    \"\"\"A small extension of TextTestResult that also collects a map of test statuses.\\n    \\n    \\n    result.results is a map from test name (string) to boolean: True(passed) or False(failed or error)\"\"\"\\n    \\n    separator1 = \\'=\\' * 70\\n    separator2 = \\'-\\' * 70\\n    \\n    def __init__(self, stream, descriptions, verbosity):\\n        super(unittest.TextTestResult, self).__init__(stream, descriptions, verbosity)\\n        # A map of test name to True(passed) or False(failed or error)\\n        self.results = {}\\n        # Copied from TextTestResult.\\n        self.stream = stream\\n        self.showAll = verbosity > 1\\n        self.dots = verbosity == 1\\n        self.descriptions = descriptions\\n\\n    def testName(self, test):\\n        \"\"\"A helper function to format the test as a human-readable string.\\n        \\n        The format is TestClassName.test_method. This is similar\\n        to TextTestResult.getDescription(test), but uses different format.\\n        getDescription: \\'test_one (__main__.HelloTest)\\'\\n        testName: \\'HelloTest.test_one\\'\\n        \"\"\"\\n        return unittest.util.strclass(test.__class__).replace(\\'__main__.\\', \\'\\') + \\'.\\' + test._testMethodName\\n        \\n    def getDescription(self, test):\\n        doc_first_line = test.shortDescription()\\n        if self.descriptions and doc_first_line:\\n            return \\'\\\\n\\'.join((str(test), doc_first_line))\\n        else:\\n            return str(test)\\n\\n    def startTest(self, test):\\n        super(unittest.TextTestResult, self).startTest(test)\\n        if self.showAll:\\n            self.stream.write(self.getDescription(test))\\n            self.stream.write(\" ... \")\\n            self.stream.flush()\\n\\n    def addSuccess(self, test):\\n        super(unittest.TextTestResult, self).addSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"ok\")\\n        elif self.dots:\\n            self.stream.write(\\'.\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = True\\n\\n    def addError(self, test, err):\\n        super(unittest.TextTestResult, self).addError(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"ERROR\")\\n        elif self.dots:\\n            self.stream.write(\\'E\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"FAIL\")\\n        elif self.dots:\\n            self.stream.write(\\'F\\')\\n            self.stream.flush()\\n        self.results[self.testName(test)] = False\\n\\n    def addSkip(self, test, reason):\\n        super(unittest.TextTestResult, self).addSkip(test, reason)\\n        if self.showAll:\\n            self.stream.writeln(\"skipped {0!r}\".format(reason))\\n        elif self.dots:\\n            self.stream.write(\"s\")\\n            self.stream.flush()\\n\\n    def addExpectedFailure(self, test, err):\\n        super(unittest.TextTestResult, self).addExpectedFailure(test, err)\\n        if self.showAll:\\n            self.stream.writeln(\"expected failure\")\\n        elif self.dots:\\n            self.stream.write(\"x\")\\n            self.stream.flush()\\n\\n    def addUnexpectedSuccess(self, test):\\n        super(unittest.TextTestResult, self).addUnexpectedSuccess(test)\\n        if self.showAll:\\n            self.stream.writeln(\"unexpected success\")\\n        elif self.dots:\\n            self.stream.write(\"u\")\\n            self.stream.flush()\\n\\n    def printErrors(self):\\n        if self.dots or self.showAll:\\n            self.stream.writeln()\\n        self.printErrorList(\\'ERROR\\', self.errors)\\n        self.printErrorList(\\'FAIL\\', self.failures)\\n\\n    def printErrorList(self, flavour, errors):\\n        for test, err in errors:\\n            self.stream.writeln(self.separator1)\\n            self.stream.writeln(\"%s: %s\" % (flavour,self.getDescription(test)))\\n            self.stream.writeln(self.separator2)\\n            self.stream.writeln(\"%s\" % err)\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloOutputTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       " '_i62': 'def hello(name):\\n    \"\"\" # BEGIN PROMPT\\n    # Please put your solution here:\\n    # return ...\\n    pass\\n    \"\"\" # END PROMPT\\n    # BEGIN SOLUTION\\n    return \"Hello, \" + name\\n    # END SOLUTION',\n",
       " '_i63': '# TEST\\nassert(hello(\"world\") == \"Hello, world\")',\n",
       " '_i64': '# The part before \"BEGIN UNITTEST\" -- preamble -- sets up the environment so that \\'submission.hello\\'\\n# is a function that we need to test. In the autograder worker environment, the preamble will be\\n# replaced with \\'import submission\\' with an assumption that the student\\'s solution will be written\\n# to the file \\'submission.py\\'.\\nsubmission = SimpleNamespace(hello=hello)\\n\\n# BEGIN UNITTEST\\n# The unit tests main part is contained between \"BEGIN UNITTEST\" and \"END UNITTEST\". It will be copied\\n# verbatim into the autograder directory, with an addition of \\'import submission;\\'\\n\\nimport unittest\\n\\nclass HelloTest(unittest.TestCase):\\n    def test_one(self):\\n        self.assertEqual(submission.hello(\"one\"), \"Hello, one\")\\n        \\n    def test_bad(self):\\n        self.assertEqual(submission.hello(\"bad\"), \"Hello, good\")\\n        \\n# END UNITTEST\\n\\nimport sys\\nimport io\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\\n# Optional.\\nprint(errors.getvalue())\\n\\nprint(result.results)',\n",
       " '_i65': '# BEGIN AUTOTEST\\n# The tests below test that the unit test suite above produces expected outcomes from\\n# TODO(salikh): Figure out the right syntax for autotests.\\ndef wrong_hello(name):\\n    return \"Bye, \" + name\\n\\nimport unittest\\n\\nsubmission.hello = wrong_hello\\nsuite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\\nerrors = io.StringIO()\\nresult = unittest.TextTestRunner(verbosity=4,stream=errors,  resultclass=SummaryTestResult).run(suite)\\n\\nprint(result.results)\\nassert(result.results[\\'HelloTest.test_bad\\'] == False)\\nassert(result.results[\\'HelloTest.test_one\\'] == False)',\n",
       " '_i66': 'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_cell_magic\\ndef submission(line, cell):\\n    \"\"\"A magic to mark a textual submission, possibly incorrect and unparseable.\"\"\"\\n    return cell\\n\\n@register_line_magic\\ndef autotest(line):\\n    \"\"\"A magic to run an auto test: run previously defined unit tests with a submission just given.\"\"\"\\n    return eval(line)\\n\\ndel submission, autotest',\n",
       " '_i67': '%%submission\\ndef syntax_error(name:\\n    return name',\n",
       " '_67': 'def syntax_error(name:\\n    return name\\n',\n",
       " '_i68': \"result = %autotest HelloTest\\nresult\\n#assert(result['HelloTest.test_bad'] == False)\",\n",
       " '_68': __main__.HelloTest,\n",
       " '_i69': 'from IPython.core.magic import (register_line_magic, register_cell_magic,\\n                                register_line_cell_magic)\\n\\n@register_line_magic\\ndef lmagic(line):\\n    \"my line magic\"\\n    return line\\n\\n@register_cell_magic\\ndef cmagic(line, cell):\\n    \"my cell magic\"\\n    return cell\\n\\ndel lmagic, cmagic',\n",
       " '_i70': 'x = %lmagic a b c\\nprint(\"Hello, \" +x)',\n",
       " '_i71': '%%cmagic\\nmy cell magic\\nasfd',\n",
       " '_71': 'my cell magic\\nasfd\\n',\n",
       " '_i72': 'vars()'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import (Magics, magics_class, line_magic,\n",
    "                                cell_magic, line_cell_magic)\n",
    "\n",
    "# The class MUST call this class decorator at creation time\n",
    "@magics_class\n",
    "class MyMagics(Magics):\n",
    "\n",
    "    @line_magic\n",
    "    def lmagic(self, line):\n",
    "        \"my line magic\"\n",
    "        print(\"Full access to the main IPython object:\", self.shell)\n",
    "        print(\"Variables in the user namespace:\", list(self.shell.user_ns.keys()))\n",
    "        return line\n",
    "\n",
    "    @cell_magic\n",
    "    def cmagic(self, line, cell):\n",
    "        \"my cell magic\"\n",
    "        return line, cell\n",
    "\n",
    "    @line_cell_magic\n",
    "    def lcmagic(self, line, cell=None):\n",
    "        \"Magic that works both as %lcmagic and as %%lcmagic\"\n",
    "        if cell is None:\n",
    "            print(\"Called as line magic\")\n",
    "            return line\n",
    "        else:\n",
    "            print(\"Called as cell magic\")\n",
    "            return line, cell\n",
    "        \n",
    "ip = get_ipython()\n",
    "ip.register_magics(MyMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full access to the main IPython object: <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7fc6f8cd84e0>\n",
      "Variables in the user namespace: ['__name__', '__doc__', '__package__', '__loader__', '__spec__', '__builtin__', '__builtins__', '_ih', '_oh', '_dh', 'In', 'Out', 'get_ipython', 'exit', 'quit', '_', '__', '___', '_i', '_ii', '_iii', '_i1', '_i2', '_i3', '_i4', '_i5', 'printHello', '_i6', 'SimpleNamespace', 'unittest', 'sys', 'io', 'contextmanager', 'StringIO', 'capture_output', 'HelloOutputTest', 'SummaryTestResult', 'suite', 'errors', 'result', '_i7', 'hello', '_i8', '_i9', 'HelloTest', '_i10', 'wrong_hello', '_i11', '_i12', 'register_line_magic', 'register_cell_magic', 'register_line_cell_magic', '_i13', '_i14', '_i15', '_15', '_i16', '_i17', '_i18', '_i19', '_i20', '_i21', '_i22', '_i23', '_i24', '_i25', '_i26', '_i27', '_i28', '_28', '_i29', '_i30', '_i31', '_31', '_i32', '_i33', '_33', '_i34', '_i35', '_35', '_i36', '_36', '_i37', '_i38', '_i39', '_i40', '_i41', '_i42', '_i43', '_i44', '_i45', '_i46', '_i47', '_i48', '_48', '_i49', '_49', '_i50', '_i51', 'x', '_i52', '_52', '_i53', '_53', '_i54', 'Magics', 'magics_class', 'line_magic', 'cell_magic', 'line_cell_magic', 'MyMagics', 'ip', '_i55', '_55', '_i56', '_i57', '_i58', '_i59', '_i60', '_i61', '_i62', '_i63', '_i64', '_i65', '_i66', '_i67', '_67', '_i68', '_68', '_i69', '_i70', '_i71', '_71', '_i72', '_72', '_i73', '_i74']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ab cd ef'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%lmagic ab cd ef"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
