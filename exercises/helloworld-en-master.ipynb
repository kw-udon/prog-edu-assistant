{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Hello world\n",
    "\n",
    "In this unit you will learn how to use Python to implement the first ever program\n",
    "that *every* programmer starts with. This also serves as an example for the master\n",
    "notebook format.\n",
    "\n",
    "```\n",
    "# All markdown cells are searched for triple-backtick blocks. Within a triple quoted block,\n",
    "# a match on /^# ASSIGNMENT METADATA/ will trigger handling this as an assignment-level metadata\n",
    "# block. The rest of the metadata is parsed as YAML and may be used e.g. for setting\n",
    "# default settings for autograder isolation (memory limit etc).\n",
    "# The assignment_id is useful to identify which assignment a submission pertains to.\n",
    "# ASSIGNMENT METADATA\n",
    "assignment_id: \"HelloWorld\"\n",
    "```\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Here is the traditional first programming exercise, called \"Hello world\".\n",
    "The task is to print the message: \"Hello, world\".\n",
    "\n",
    "Here are a few examples to get you started. Run the following cells and see how\n",
    "you can print a message. To run a cell, click with mouse inside a cell, then\n",
    "press Ctrl+Enter to execute it. If you want to execute a few cells sequentially,\n",
    "then press Shift+Enter instead, and the focus will be automatically moved\n",
    "to the next cell as soon as one cell finishes execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bye bye\n"
     ]
    }
   ],
   "source": [
    "print(\"bye bye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey you\n"
     ]
    }
   ],
   "source": [
    "print(\"hey\", \"you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n",
      "two\n"
     ]
    }
   ],
   "source": [
    "print(\"one\")\n",
    "print(\"two\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: printing greeting\n",
    "\n",
    "```\n",
    "# The markdown cell with triple-backtick block matching /^# EXERCISE METADATA/ is an exercise-level\n",
    "# metadata. The next block is assumed to be the solution block, and will get annotated with\n",
    "# the exercise_id.\n",
    "# EXERCISE METADATA\n",
    "exercise_id: \"hello1\"\n",
    "```\n",
    "\n",
    "Now it is your turn. Please create a program in the next cell that would print a message \"Hello, world\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # BEGIN PROMPT\n",
    "   # ... put your program here\n",
    "   pass\n",
    "\"\"\" # END PROMPT\n",
    "def printHello():\n",
    "    # BEGIN SOLUTION\n",
    "    print(\"Hello, world\")\n",
    "    # END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_output (__main__.HelloOutputTest) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "{'HelloOutputTest.test_output': True}\n"
     ]
    }
   ],
   "source": [
    "# This will not be included in the student notebook because of BEGIN UNITTEST marker below.\n",
    "\n",
    "# Imitate the 'import submission' environment with ad-hoc object.\n",
    "from types import SimpleNamespace\n",
    "submission = SimpleNamespace(printHello=printHello)\n",
    "\n",
    "# BEGIN UNITTEST\n",
    "import unittest\n",
    "\n",
    "import sys\n",
    "import io\n",
    "from contextlib import contextmanager\n",
    "from io import StringIO\n",
    "\n",
    "@contextmanager\n",
    "def capture_output():\n",
    "    capture_out, capture_err = StringIO(), StringIO()\n",
    "    save_out, save_err = sys.stdout, sys.stderr\n",
    "    try:\n",
    "        sys.stdout, sys.stderr = capture_out, capture_err\n",
    "        yield sys.stdout, sys.stderr\n",
    "    finally:\n",
    "        sys.stdout, sys.stderr = save_out, save_err\n",
    "\n",
    "class HelloOutputTest(unittest.TestCase):\n",
    "    def test_output(self):\n",
    "        with capture_output() as (out, err):\n",
    "            submission.printHello()\n",
    "        self.assertEqual(err.getvalue(), \"\")\n",
    "        self.assertEqual(out.getvalue(), \"Hello, world\\n\")\n",
    "\n",
    "# END UNITTEST\n",
    "\n",
    "# The parts after END UNITTEST are executed in the notebook environment, but not copied\n",
    "# to the autograder scripts or to student notebooks.\n",
    "\n",
    "# TODO(salikh): Move this into a shared library and make that library installable via pip.\n",
    "class SummaryTestResult(unittest.TextTestResult):\n",
    "    \"\"\"A small extension of TextTestResult that also collects a map of test statuses.\n",
    "    \n",
    "    \n",
    "    result.results is a map from test name (string) to boolean: True(passed) or False(failed or error)\"\"\"\n",
    "    \n",
    "    separator1 = '=' * 70\n",
    "    separator2 = '-' * 70\n",
    "    \n",
    "    def __init__(self, stream, descriptions, verbosity):\n",
    "        super(unittest.TextTestResult, self).__init__(stream, descriptions, verbosity)\n",
    "        # A map of test name to True(passed) or False(failed or error)\n",
    "        self.results = {}\n",
    "        # Copied from TextTestResult.\n",
    "        self.stream = stream\n",
    "        self.showAll = verbosity > 1\n",
    "        self.dots = verbosity == 1\n",
    "        self.descriptions = descriptions\n",
    "\n",
    "    def testName(self, test):\n",
    "        \"\"\"A helper function to format the test as a human-readable string.\n",
    "        \n",
    "        The format is TestClassName.test_method. This is similar\n",
    "        to TextTestResult.getDescription(test), but uses different format.\n",
    "        getDescription: 'test_one (__main__.HelloTest)'\n",
    "        testName: 'HelloTest.test_one'\n",
    "        \"\"\"\n",
    "        return unittest.util.strclass(test.__class__).replace('__main__.', '') + '.' + test._testMethodName\n",
    "        \n",
    "    def getDescription(self, test):\n",
    "        doc_first_line = test.shortDescription()\n",
    "        if self.descriptions and doc_first_line:\n",
    "            return '\\n'.join((str(test), doc_first_line))\n",
    "        else:\n",
    "            return str(test)\n",
    "\n",
    "    def startTest(self, test):\n",
    "        super(unittest.TextTestResult, self).startTest(test)\n",
    "        if self.showAll:\n",
    "            self.stream.write(self.getDescription(test))\n",
    "            self.stream.write(\" ... \")\n",
    "            self.stream.flush()\n",
    "\n",
    "    def addSuccess(self, test):\n",
    "        super(unittest.TextTestResult, self).addSuccess(test)\n",
    "        if self.showAll:\n",
    "            self.stream.writeln(\"ok\")\n",
    "        elif self.dots:\n",
    "            self.stream.write('.')\n",
    "            self.stream.flush()\n",
    "        self.results[self.testName(test)] = True\n",
    "\n",
    "    def addError(self, test, err):\n",
    "        super(unittest.TextTestResult, self).addError(test, err)\n",
    "        if self.showAll:\n",
    "            self.stream.writeln(\"ERROR\")\n",
    "        elif self.dots:\n",
    "            self.stream.write('E')\n",
    "            self.stream.flush()\n",
    "        self.results[self.testName(test)] = False\n",
    "\n",
    "    def addFailure(self, test, err):\n",
    "        super(unittest.TextTestResult, self).addFailure(test, err)\n",
    "        if self.showAll:\n",
    "            self.stream.writeln(\"FAIL\")\n",
    "        elif self.dots:\n",
    "            self.stream.write('F')\n",
    "            self.stream.flush()\n",
    "        self.results[self.testName(test)] = False\n",
    "\n",
    "    def addSkip(self, test, reason):\n",
    "        super(unittest.TextTestResult, self).addSkip(test, reason)\n",
    "        if self.showAll:\n",
    "            self.stream.writeln(\"skipped {0!r}\".format(reason))\n",
    "        elif self.dots:\n",
    "            self.stream.write(\"s\")\n",
    "            self.stream.flush()\n",
    "\n",
    "    def addExpectedFailure(self, test, err):\n",
    "        super(unittest.TextTestResult, self).addExpectedFailure(test, err)\n",
    "        if self.showAll:\n",
    "            self.stream.writeln(\"expected failure\")\n",
    "        elif self.dots:\n",
    "            self.stream.write(\"x\")\n",
    "            self.stream.flush()\n",
    "\n",
    "    def addUnexpectedSuccess(self, test):\n",
    "        super(unittest.TextTestResult, self).addUnexpectedSuccess(test)\n",
    "        if self.showAll:\n",
    "            self.stream.writeln(\"unexpected success\")\n",
    "        elif self.dots:\n",
    "            self.stream.write(\"u\")\n",
    "            self.stream.flush()\n",
    "\n",
    "    def printErrors(self):\n",
    "        if self.dots or self.showAll:\n",
    "            self.stream.writeln()\n",
    "        self.printErrorList('ERROR', self.errors)\n",
    "        self.printErrorList('FAIL', self.failures)\n",
    "\n",
    "    def printErrorList(self, flavour, errors):\n",
    "        for test, err in errors:\n",
    "            self.stream.writeln(self.separator1)\n",
    "            self.stream.writeln(\"%s: %s\" % (flavour,self.getDescription(test)))\n",
    "            self.stream.writeln(self.separator2)\n",
    "            self.stream.writeln(\"%s\" % err)\n",
    "\n",
    "import sys\n",
    "import io\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(HelloOutputTest)\n",
    "errors = io.StringIO()\n",
    "result = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\n",
    "# Optional.\n",
    "print(errors.getvalue())\n",
    "\n",
    "print(result.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: returning greeting as value\n",
    "\n",
    "```\n",
    "# EXERCISE METADATA\n",
    "exercise_id: \"hello2\"\n",
    "```\n",
    "\n",
    "Please create a function that given a name string returns a string with a greeting,\n",
    "For example, for input `\"world\"` it should return `\"Hello, world\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello(name):\n",
    "    \"\"\" # BEGIN PROMPT\n",
    "    # Please put your solution here:\n",
    "    # return ...\n",
    "    pass\n",
    "    \"\"\" # END PROMPT\n",
    "    # BEGIN SOLUTION\n",
    "    return \"Hello, \" + name\n",
    "    # END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert(hello(\"world\") == \"Hello, world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A code cell marked with `\"# TEST\"` will be converted into a unit test for the solution. It will also be preserved in the student version of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_bad (__main__.HelloTest) ... FAIL\n",
      "test_one (__main__.HelloTest) ... ok\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_bad (__main__.HelloTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-9-6dbf578cd0e2>\", line 18, in test_bad\n",
      "    self.assertEqual(submission.hello(\"bad\"), \"Hello, good\")\n",
      "AssertionError: 'Hello, bad' != 'Hello, good'\n",
      "- Hello, bad\n",
      "?        ^^\n",
      "+ Hello, good\n",
      "?        ^^^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "{'HelloTest.test_bad': False, 'HelloTest.test_one': True}\n"
     ]
    }
   ],
   "source": [
    "# The part before \"BEGIN UNITTEST\" -- preamble -- sets up the environment so that 'submission.hello'\n",
    "# is a function that we need to test. In the autograder worker environment, the preamble will be\n",
    "# replaced with 'import submission' with an assumption that the student's solution will be written\n",
    "# to the file 'submission.py'.\n",
    "submission = SimpleNamespace(hello=hello)\n",
    "\n",
    "# BEGIN UNITTEST\n",
    "# The unit tests main part is contained between \"BEGIN UNITTEST\" and \"END UNITTEST\". It will be copied\n",
    "# verbatim into the autograder directory, with an addition of 'import submission;'\n",
    "\n",
    "import unittest\n",
    "\n",
    "class HelloTest(unittest.TestCase):\n",
    "    def test_one(self):\n",
    "        self.assertEqual(submission.hello(\"one\"), \"Hello, one\")\n",
    "        \n",
    "    def test_bad(self):\n",
    "        self.assertEqual(submission.hello(\"bad\"), \"Hello, good\")\n",
    "        \n",
    "# END UNITTEST\n",
    "\n",
    "import sys\n",
    "import io\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\n",
    "errors = io.StringIO()\n",
    "result = unittest.TextTestRunner(verbosity=4,stream=errors, resultclass=SummaryTestResult).run(suite)\n",
    "# Optional.\n",
    "print(errors.getvalue())\n",
    "\n",
    "print(result.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HelloTest.test_bad': False, 'HelloTest.test_one': False}\n"
     ]
    }
   ],
   "source": [
    "# BEGIN AUTOTEST\n",
    "# The tests below test that the unit test suite above produces expected outcomes from\n",
    "# TODO(salikh): Figure out the right syntax for autotests.\n",
    "def wrong_hello(name):\n",
    "    return \"Bye, \" + name\n",
    "\n",
    "import unittest\n",
    "\n",
    "submission.hello = wrong_hello\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(HelloTest)\n",
    "errors = io.StringIO()\n",
    "result = unittest.TextTestRunner(verbosity=4,stream=errors,  resultclass=SummaryTestResult).run(suite)\n",
    "\n",
    "print(result.results)\n",
    "assert(result.results['HelloTest.test_bad'] == False)\n",
    "assert(result.results['HelloTest.test_one'] == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import (register_line_magic, register_cell_magic,\n",
    "                                register_line_cell_magic)\n",
    "\n",
    "@register_line_magic\n",
    "def lmagic(line):\n",
    "    \"my line magic\"\n",
    "    return line\n",
    "\n",
    "@register_cell_magic\n",
    "def cmagic(line, cell):\n",
    "    \"my cell magic\"\n",
    "    return cell\n",
    "\n",
    "del lmagic, cmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my cell magic\\nasfd\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%cmagic\n",
    "my cell magic\n",
    "asfd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
